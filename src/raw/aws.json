{"kind": "Listing", "data": {"modhash": "", "dist": 10, "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "", "author_fullname": "t2_9qydp", "saved": false, "mod_reason_title": null, "gilded": 1, "clicked": false, "title": "AWS VP &amp; Distinguished Engineer Tim Bray resigns over worker treatment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "article", "downs": 0, "hide_score": false, "name": "t3_gde37f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 360, "total_awards_received": 2, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "article", "can_mod_post": false, "score": 360, "approved_by": null, "author_premium": true, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_2": 1}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1588636402.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "tbray.org", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": 0, "coin_price": 500, "id": "gid_2", "penny_donate": null, "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png", "days_of_premium": 7, "icon_height": 512, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_width": 512, "start_date": null, "is_enabled": true, "description": "Gives the author a week of Reddit Premium, %{coin_symbol}100 Coins to do with as they please, and shows a Gold Award.", "end_date": null, "subreddit_coin_reward": 0, "count": 1, "name": "Gold", "icon_format": null, "award_sub_type": "GLOBAL", "penny_price": null, "award_type": "global"}, {"giver_coin_reward": 0, "subreddit_id": null, "is_new": false, "days_of_drip_extension": 0, "coin_price": 50, "id": "award_251da2ac-143b-4794-91f8-b21fc06fdb52", "penny_donate": 0, "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/FlattenCurve_512.png", "days_of_premium": 0, "icon_height": 512, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/FlattenCurve_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/FlattenCurve_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/FlattenCurve_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/FlattenCurve_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/FlattenCurve_128.png", "width": 128, "height": 128}], "icon_width": 512, "start_date": null, "is_enabled": true, "description": "When it's time to work together responsibly to minimize the spread.", "end_date": null, "subreddit_coin_reward": 0, "count": 1, "name": "Flatten the Curve", "icon_format": "APNG", "award_sub_type": "GLOBAL", "penny_price": 0, "award_type": "global"}], "awarders": [], "media_only": false, "link_flair_template_id": "85ab6b1a-b9e3-11e6-847a-0e8ffa087616", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gde37f", "is_robot_indexable": true, "report_reasons": null, "author": "caller-number-four", "discussion_type": null, "num_comments": 55, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gde37f/aws_vp_distinguished_engineer_tim_bray_resigns/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.tbray.org/ongoing/When/202x/2020/04/29/Leaving-Amazon", "subreddit_subscribers": 120885, "created_utc": 1588607602.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "I am developing an app and one of the processes (which is critical) is invoking a web service which returns JSON information. Every invocation of this JSON service involves a cost (say 10p).\n\nThe information returned (about a vehicle) I want to cache in AWS. If a customer returns to the app with the same vehicle details, then it can be retrieved from the cache and avoid the company being charged the fee.\n\nIs there a suitable service for this that would also be more performant? I was/am looking at something like S3 or Dynamo DB.\n\nThanks!", "author_fullname": "t2_11ll5n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cache for JSON data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "hide_score": true, "name": "t3_gdwx9h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "technical question", "can_mod_post": false, "score": 2, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1588710879.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am developing an app and one of the processes (which is critical) is invoking a web service which returns JSON information. Every invocation of this JSON service involves a cost (say 10p).&lt;/p&gt;\n\n&lt;p&gt;The information returned (about a vehicle) I want to cache in AWS. If a customer returns to the app with the same vehicle details, then it can be retrieved from the cache and avoid the company being charged the fee.&lt;/p&gt;\n\n&lt;p&gt;Is there a suitable service for this that would also be more performant? I was/am looking at something like S3 or Dynamo DB.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "e0acaab0-fe51-11e8-b457-0e86fa5111f4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gdwx9h", "is_robot_indexable": true, "report_reasons": null, "author": "GSS55", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gdwx9h/cache_for_json_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gdwx9h/cache_for_json_data/", "subreddit_subscribers": 120885, "created_utc": 1588682079.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "In Simply Month calculator i can type the number of ALB's that i want to calculate. Is ALB with a NIC in AZ1 and  a NIC in AZ2 for Multi AZ one ALB Loadbalancer regarding calculations or counts this as 2 ALBs?", "author_fullname": "t2_hzv5q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS ELB in two AZ's costs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "hide_score": true, "name": "t3_gdwrt7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "networking", "can_mod_post": false, "score": 2, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1588710233.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In Simply Month calculator i can type the number of ALB&amp;#39;s that i want to calculate. Is ALB with a NIC in AZ1 and  a NIC in AZ2 for Multi AZ one ALB Loadbalancer regarding calculations or counts this as 2 ALBs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "fa6637dc-fe51-11e8-b451-0e432432760c", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gdwrt7", "is_robot_indexable": true, "report_reasons": null, "author": "tomsonxxx", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gdwrt7/aws_elb_in_two_azs_costs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gdwrt7/aws_elb_in_two_azs_costs/", "subreddit_subscribers": 120885, "created_utc": 1588681433.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "", "author_fullname": "t2_3sopw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NoSQL Workbench for DynamoDB adds support for Linux--data modeling, querying, testing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "hide_score": false, "name": "t3_gdm9ok", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "database", "can_mod_post": false, "score": 15, "approved_by": null, "author_premium": true, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1588662365.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "aws.amazon.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "c67223e6-fe51-11e8-96e8-0e985e0a8712", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gdm9ok", "is_robot_indexable": true, "report_reasons": null, "author": "yutfree", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gdm9ok/nosql_workbench_for_dynamodb_adds_support_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://aws.amazon.com/about-aws/whats-new/2020/05/nosql-workbench-for-dynamodb-adds-support-for-linux/", "subreddit_subscribers": 120885, "created_utc": 1588633565.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "* Ubuntu 18.04 (ARM)\n* s3fs v1.86\n* I've double checked to ensure the user has a policy that allows access to the S3 bucket (I've actually given the account admin while I try to work through this)\n* EC2 instance has a role that allows access to the S3 bucket (again admin as I try to resolve this)\n* I created the password file with my access key ID and secret access key and CHMOD 600 for the password file\n* I run **sudo s3fs my-bucket /home/ubuntu/efs\\_uploads -o passwd\\_file=${HOME}/.passwd-s3fs -o dbglevel=info -f -o curldbg** and it runs until it hangs up after the following two lines \n\n\\[INF\\]  curl.cpp:RequestPerform(2455): HTTP response code 200\n\n\\[INF\\] curl.cpp:ReturnHandler(318): Pool full: destroy the oldest handler\n\n* In version 1.84 of s3fs it stopped on the first line and never reached the line about curl.cpp.ReturnHandler(318)...\n\nI've seen others post about this on GitHub but I haven't seen any solutions", "author_fullname": "t2_30ygosus", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Having Trouble Mounting S3 Bucket to EC2 Instance Using s3fs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "hide_score": true, "name": "t3_gdxgh3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "storage", "can_mod_post": false, "score": 1, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1588713116.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ul&gt;\n&lt;li&gt;Ubuntu 18.04 (ARM)&lt;/li&gt;\n&lt;li&gt;s3fs v1.86&lt;/li&gt;\n&lt;li&gt;I&amp;#39;ve double checked to ensure the user has a policy that allows access to the S3 bucket (I&amp;#39;ve actually given the account admin while I try to work through this)&lt;/li&gt;\n&lt;li&gt;EC2 instance has a role that allows access to the S3 bucket (again admin as I try to resolve this)&lt;/li&gt;\n&lt;li&gt;I created the password file with my access key ID and secret access key and CHMOD 600 for the password file&lt;/li&gt;\n&lt;li&gt;I run &lt;strong&gt;sudo s3fs my-bucket /home/ubuntu/efs_uploads -o passwd_file=${HOME}/.passwd-s3fs -o dbglevel=info -f -o curldbg&lt;/strong&gt; and it runs until it hangs up after the following two lines &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;[INF]  curl.cpp:RequestPerform(2455): HTTP response code 200&lt;/p&gt;\n\n&lt;p&gt;[INF] curl.cpp:ReturnHandler(318): Pool full: destroy the oldest handler&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;In version 1.84 of s3fs it stopped on the first line and never reached the line about curl.cpp.ReturnHandler(318)...&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;ve seen others post about this on GitHub but I haven&amp;#39;t seen any solutions&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "cb32bd78-fe51-11e8-8357-0e3adcef64d8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gdxgh3", "is_robot_indexable": true, "report_reasons": null, "author": "ImRonEffingSwanson", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gdxgh3/having_trouble_mounting_s3_bucket_to_ec2_instance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gdxgh3/having_trouble_mounting_s3_bucket_to_ec2_instance/", "subreddit_subscribers": 120885, "created_utc": 1588684316.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "Let's say I have a 10GB EBS volume, using 5GB of capacity. I take daily backups, where there is negligible change to the disk, and I copy these backups from Singapore to Sydney.\n\nAssumption #1: The original snapshot size is \\~5GB as it only takes consumed data.\n\nAssumption #2: My daily Singapore snapshots, all together, consume only \\~5GB as no changes are being made.\n\nAssumption #3: My daily Sydney snapshot copies, all together, consume only \\~5GB as no changes are made **and** I'm only charged \\~5GB of transfer to Sydney as all future backups have no change.\n\nI'm fairly confident in #1 and #2, and I'm completely unsure of #3.\n\nAny assistance would be wonderful, thanks!", "author_fullname": "t2_eiss2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Clarity on EBS Incremental Snapshots &amp; Cross-Region Copy Pricing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "hide_score": true, "name": "t3_gdxge4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "billing", "can_mod_post": false, "score": 1, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1588713109.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say I have a 10GB EBS volume, using 5GB of capacity. I take daily backups, where there is negligible change to the disk, and I copy these backups from Singapore to Sydney.&lt;/p&gt;\n\n&lt;p&gt;Assumption #1: The original snapshot size is ~5GB as it only takes consumed data.&lt;/p&gt;\n\n&lt;p&gt;Assumption #2: My daily Singapore snapshots, all together, consume only ~5GB as no changes are being made.&lt;/p&gt;\n\n&lt;p&gt;Assumption #3: My daily Sydney snapshot copies, all together, consume only ~5GB as no changes are made &lt;strong&gt;and&lt;/strong&gt; I&amp;#39;m only charged ~5GB of transfer to Sydney as all future backups have no change.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m fairly confident in #1 and #2, and I&amp;#39;m completely unsure of #3.&lt;/p&gt;\n\n&lt;p&gt;Any assistance would be wonderful, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b130294a-1811-11e9-a2ef-0e49548b5cda", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gdxge4", "is_robot_indexable": true, "report_reasons": null, "author": "FinallyAFreeMind", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gdxge4/clarity_on_ebs_incremental_snapshots_crossregion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gdxge4/clarity_on_ebs_incremental_snapshots_crossregion/", "subreddit_subscribers": 120885, "created_utc": 1588684309.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "", "author_fullname": "t2_iq3ct", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS VPC for Software Engineers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "article", "downs": 0, "hide_score": false, "name": "t3_gdv6kv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "article", "can_mod_post": false, "score": 1, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1588702655.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.deleu.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "85ab6b1a-b9e3-11e6-847a-0e8ffa087616", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gdv6kv", "is_robot_indexable": true, "report_reasons": null, "author": "Deleugpn", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gdv6kv/aws_vpc_for_software_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.deleu.dev/aws-vpc-for-software-engineers/", "subreddit_subscribers": 120885, "created_utc": 1588673855.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "Hello,\n\nI setup a new service that has to write it's logs to AWS CloudWatch in order to be ingested into our SIEM.  I don't want to keep them inside CloudWatch for more than a few days due to the sheer size of the logs, so I want to automate exporting them to S3 for long term storage.\n\nI know there are several methods to do this, with the following coming to mind:\n\n* Lambda/Step Function to automate exporting to S3.\n* Kinesis Firehose\n\nWhich option is the most cost effective, at about \\~200 events per second on average and growing?\n\n  \nThanks!", "author_fullname": "t2_3hzzl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question on cost effective exporting of CloudWatch Logs to S3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "hide_score": false, "name": "t3_gdo6mj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "technical question", "can_mod_post": false, "score": 5, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1588669482.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I setup a new service that has to write it&amp;#39;s logs to AWS CloudWatch in order to be ingested into our SIEM.  I don&amp;#39;t want to keep them inside CloudWatch for more than a few days due to the sheer size of the logs, so I want to automate exporting them to S3 for long term storage.&lt;/p&gt;\n\n&lt;p&gt;I know there are several methods to do this, with the following coming to mind:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Lambda/Step Function to automate exporting to S3.&lt;/li&gt;\n&lt;li&gt;Kinesis Firehose&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Which option is the most cost effective, at about ~200 events per second on average and growing?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "e0acaab0-fe51-11e8-b457-0e86fa5111f4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gdo6mj", "is_robot_indexable": true, "report_reasons": null, "author": "skitzot", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gdo6mj/question_on_cost_effective_exporting_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gdo6mj/question_on_cost_effective_exporting_of/", "subreddit_subscribers": 120885, "created_utc": 1588640682.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "", "author_fullname": "t2_3jfxgxrh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Webscraper on steroids, using 2,000 Lambda invokes to scan 1,000,000 websites in under 7 minutes.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "hide_score": false, "name": "t3_gd6xss", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 90, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "serverless", "can_mod_post": false, "score": 90, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "Python", "selftext": "I built this a while back, but over the long weekend went back to tweak the outputs. Manage to download the robots.txt  file from 1 Million websites in under 7 minutes (start to finish) --  with finish meaning the final 400+MB file is downloaded to the local machine.\n\nThe goal of the project,  is to be fast (nothing more!), and so far, this is the fastest I've  managed to get it to run. It spins up 2000 lambda invocations, but using  SQS to stagger the invocations over a short period. 100% written in python.\n\nThis isn't a serious project, just a fun weekend thing. Let me know your thoughts!!\n\n[https://github.com/keithrozario/potassium40](https://github.com/keithrozario/potassium40)", "author_fullname": "t2_3jfxgxrh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A serverless web scraper built on the lambda super-computer using Python.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/Python", "hidden": false, "pwls": 6, "link_flair_css_class": "made-this", "downs": 0, "hide_score": false, "name": "t3_gcq18f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "I Made This", "can_mod_post": false, "score": 29, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1588538867.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.Python", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I built this a while back, but over the long weekend went back to tweak the outputs. Manage to download the robots.txt  file from 1 Million websites in under 7 minutes (start to finish) --  with finish meaning the final 400+MB file is downloaded to the local machine.&lt;/p&gt;\n\n&lt;p&gt;The goal of the project,  is to be fast (nothing more!), and so far, this is the fastest I&amp;#39;ve  managed to get it to run. It spins up 2000 lambda invocations, but using  SQS to stagger the invocations over a short period. 100% written in python.&lt;/p&gt;\n\n&lt;p&gt;This isn&amp;#39;t a serious project, just a fun weekend thing. Let me know your thoughts!!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/keithrozario/potassium40\"&gt;https://github.com/keithrozario/potassium40&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d7dfae22-4113-11ea-b9fe-0e741fe75651", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh0y", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "gcq18f", "is_robot_indexable": true, "report_reasons": null, "author": "keithrozario", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/Python/comments/gcq18f/a_serverless_web_scraper_built_on_the_lambda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/Python/comments/gcq18f/a_serverless_web_scraper_built_on_the_lambda/", "subreddit_subscribers": 565499, "created_utc": 1588510067.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1588605557.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.Python", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ff0e4f90-fe51-11e8-995f-0e494176cf40", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gd6xss", "is_robot_indexable": true, "stickied": false, "author": "keithrozario", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_gcq18f", "author_flair_text_color": null, "permalink": "/r/aws/comments/gd6xss/webscraper_on_steroids_using_2000_lambda_invokes/", "parent_whitelist_status": "all_ads", "report_reasons": null, "url": "/r/Python/comments/gcq18f/a_serverless_web_scraper_built_on_the_lambda/", "subreddit_subscribers": 120885, "created_utc": 1588576757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "We have our data stored in Redshift but recently were asked to find a solution to allow clients to query their own databases that we host (read access). Are there any  browser tools that allow this direct querying where we don't need to pay per query? (since we're already paying for redshift...) Let me know if I need to provide any additional information.", "author_fullname": "t2_3s5jr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Allowing external users to query redshift in browser", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "hide_score": false, "name": "t3_gdt8uh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "technical question", "can_mod_post": false, "score": 1, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1588692644.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have our data stored in Redshift but recently were asked to find a solution to allow clients to query their own databases that we host (read access). Are there any  browser tools that allow this direct querying where we don&amp;#39;t need to pay per query? (since we&amp;#39;re already paying for redshift...) Let me know if I need to provide any additional information.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "e0acaab0-fe51-11e8-b457-0e86fa5111f4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gdt8uh", "is_robot_indexable": true, "report_reasons": null, "author": "n3cr0ph4g1st", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gdt8uh/allowing_external_users_to_query_redshift_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gdt8uh/allowing_external_users_to_query_redshift_in/", "subreddit_subscribers": 120885, "created_utc": 1588663844.0, "num_crossposts": 0, "media": null, "is_video": false}}], "after": "t3_gdt8uh", "before": null}}