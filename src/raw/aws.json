{"kind": "Listing", "data": {"modhash": "", "dist": 11, "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "I can't describe how horrible this experience was.  I am not looking forward to how much work I am going to have to do to get my money back.  This is not my first AWS certification (I have SA Pro and DevOps Pro), but is my first online exam.  The short version is: Don't take AWS exams via the Pearson Vue at home option, even if it is offered.  AWS should not be offering this option as I can attest it is a waste of time.  Ironically, AWS would have us use their services because of their high availability and scaling but apparently they don't ask their test partners to do the same!\n\nIt started off easy enough: I passed the initial 'checks' as it confirmed my internet speed, camera access, and microphone access.  I started the process 15+ minutes before my scheduled exam time.  I was able to open the app, it again verified the technical requirements passed, and I went to the next screen.  It asked for my cell phone number and texted me a link which opened a web page which requested to take my photo.  Easy enough.  I did that and then the web page went to 'Uploading and verifying photo'.  A spinning circle started spinning.  This is where my test experience ended, but not where the poor experience ends.  I tried again, and then a third time.  Same experience.  As I write this, I left it on that page and the spinning is continuing.  This screen has been spinning for no less than 45 minutes.  At 8 minutes before my scheduled exam, I tried finding the help link.  A chat window opened, and I waited, and waited, and waited.  Still waiting as I write this.  My chat window has been open for 52 minutes and still no one to help.  Every two minutes I get ' All agents are currently assisting others. Thank you for your patience.' written in the window.  OK - what next?  They make it harder to find, but I got a phone number I can call.  I tried calling that.  Busy signal.  For the next 20 minutes I called back and back, busy signal.  Finally, I got it to actually pick up, but of course no human yet.  No estimate of time to when I can be helped.  They don't even have nice elevator music to listen to.  Who knows when I will be able to talk to someone.  This has been an exceedingly poor experience.\n\nIf you value your time, please do yourself a favor and don't even attempt a online exam with Pearson.  I worked hard to prepare for this exam and rescheduled things to fit around it.  Now, I will have to do that all again.\n\nu/jeffbarr Is this the experience AWS is hoping to get with their testing partners?  This was a waste of my time and money.  Amazon should seriously reevaluate the quality of their test partners.  I understand everyone is trying to deal with all the issues.  However, if you can't offer quality testing, then please don't offer the option at all.  It isn't respectful to people's time.  Pearson is well aware of their capacity and if it isn't up to requirements, they shouldn't be scheduling test slots.\n\n&amp;#x200B;\n\n*EDIT*: A few background items I didn't initially share that may be relevant for others.  For the computer, I used a fully up to date Windows 10 laptop.  The laptop itself is only about a month old and is in near pristine condition.  Other than a few applications like Office, there is barely anything installed on there yet.  I used a hard wired connection, like recommended by Pearson through the use of a usb-to-ethernet adapter.  I have Verizon FIOS (980Mbps/840Mbps) and did do a speed test way after it was apparent this would not work.  I forget the exact numbers, but I was still pulling in hundreds of Mbps in both directions, despite everyone being at home and using the USB ethernet adapater which does put a cap on my speed, but I can't see hundreds of Mbps not being sufficent by orders of magnatude.  My phone is a fully up to date pixel 3.  I tried using my wifi in my house first (connected through FIOS), and then using the phone 4G LTE connection.  I can't imagine this was caused by my end.  It seemed like Pearson's servers were jammed at that point in time.\n\n&amp;#x200B;\n\n*Update*: After a LONG time, I did eventually get someone to answer from Pearson.  They were nice enough and were fairly easy to understand, although there was an delay echo introduced where whatever I said was echoed a quarter to half second later which was annoying, but bearable.  I was just happy she was able to hear me.  She said she could open a trouble ticket for me, but as it was well over an hour trying to get through to any human and doubtful it was on my side, I just told her to schedule me for the next available in person appointment.  She had to cancel my appointment and then rebook it as their sub-standard system wouldn't let her reschedule an at home appointment to at a location.  Surprisingly, she said they would refund my money and rebook me.  It was painless enough, but when I asked for a reference number on the refund, all she could do is say I 'should' get an email.  Perhaps unsurprisingly, this morning I see a fully posted charge for the rescheduled exam, but no sign of a refund.  Sigh.  I will give it a few days and then start this process over.\n\nFor what its worth, people should IGNORE the advice that the web chat is the fastest way of getting help.  Find the phone number and dial and re-dial it as fast as you can when you get a busy signal.  Despite the fact that it took 20+ minutes to get the number to pickup (and was 'waiting' 20 minutes less from the phones point of view) I got a faster response from someone on the phone.  Web based chat never picked up, even though I left it running during my entire phone conversation.\n\n*Update #2*: It took two more days than the charge, but the refund did show up in the correct amount on my credit card.  I am actually quite surprised.", "author_fullname": "t2_43vca68k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PSA: Don't take remote exams offered by Pearson Vue (OnVue) for AWS Certifications!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_fscq7v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 65, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "training/certification", "can_mod_post": false, "score": 65, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": 1585824763.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1585689396.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I can&amp;#39;t describe how horrible this experience was.  I am not looking forward to how much work I am going to have to do to get my money back.  This is not my first AWS certification (I have SA Pro and DevOps Pro), but is my first online exam.  The short version is: Don&amp;#39;t take AWS exams via the Pearson Vue at home option, even if it is offered.  AWS should not be offering this option as I can attest it is a waste of time.  Ironically, AWS would have us use their services because of their high availability and scaling but apparently they don&amp;#39;t ask their test partners to do the same!&lt;/p&gt;\n\n&lt;p&gt;It started off easy enough: I passed the initial &amp;#39;checks&amp;#39; as it confirmed my internet speed, camera access, and microphone access.  I started the process 15+ minutes before my scheduled exam time.  I was able to open the app, it again verified the technical requirements passed, and I went to the next screen.  It asked for my cell phone number and texted me a link which opened a web page which requested to take my photo.  Easy enough.  I did that and then the web page went to &amp;#39;Uploading and verifying photo&amp;#39;.  A spinning circle started spinning.  This is where my test experience ended, but not where the poor experience ends.  I tried again, and then a third time.  Same experience.  As I write this, I left it on that page and the spinning is continuing.  This screen has been spinning for no less than 45 minutes.  At 8 minutes before my scheduled exam, I tried finding the help link.  A chat window opened, and I waited, and waited, and waited.  Still waiting as I write this.  My chat window has been open for 52 minutes and still no one to help.  Every two minutes I get &amp;#39; All agents are currently assisting others. Thank you for your patience.&amp;#39; written in the window.  OK - what next?  They make it harder to find, but I got a phone number I can call.  I tried calling that.  Busy signal.  For the next 20 minutes I called back and back, busy signal.  Finally, I got it to actually pick up, but of course no human yet.  No estimate of time to when I can be helped.  They don&amp;#39;t even have nice elevator music to listen to.  Who knows when I will be able to talk to someone.  This has been an exceedingly poor experience.&lt;/p&gt;\n\n&lt;p&gt;If you value your time, please do yourself a favor and don&amp;#39;t even attempt a online exam with Pearson.  I worked hard to prepare for this exam and rescheduled things to fit around it.  Now, I will have to do that all again.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"/u/jeffbarr\"&gt;u/jeffbarr&lt;/a&gt; Is this the experience AWS is hoping to get with their testing partners?  This was a waste of my time and money.  Amazon should seriously reevaluate the quality of their test partners.  I understand everyone is trying to deal with all the issues.  However, if you can&amp;#39;t offer quality testing, then please don&amp;#39;t offer the option at all.  It isn&amp;#39;t respectful to people&amp;#39;s time.  Pearson is well aware of their capacity and if it isn&amp;#39;t up to requirements, they shouldn&amp;#39;t be scheduling test slots.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;EDIT&lt;/em&gt;: A few background items I didn&amp;#39;t initially share that may be relevant for others.  For the computer, I used a fully up to date Windows 10 laptop.  The laptop itself is only about a month old and is in near pristine condition.  Other than a few applications like Office, there is barely anything installed on there yet.  I used a hard wired connection, like recommended by Pearson through the use of a usb-to-ethernet adapter.  I have Verizon FIOS (980Mbps/840Mbps) and did do a speed test way after it was apparent this would not work.  I forget the exact numbers, but I was still pulling in hundreds of Mbps in both directions, despite everyone being at home and using the USB ethernet adapater which does put a cap on my speed, but I can&amp;#39;t see hundreds of Mbps not being sufficent by orders of magnatude.  My phone is a fully up to date pixel 3.  I tried using my wifi in my house first (connected through FIOS), and then using the phone 4G LTE connection.  I can&amp;#39;t imagine this was caused by my end.  It seemed like Pearson&amp;#39;s servers were jammed at that point in time.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Update&lt;/em&gt;: After a LONG time, I did eventually get someone to answer from Pearson.  They were nice enough and were fairly easy to understand, although there was an delay echo introduced where whatever I said was echoed a quarter to half second later which was annoying, but bearable.  I was just happy she was able to hear me.  She said she could open a trouble ticket for me, but as it was well over an hour trying to get through to any human and doubtful it was on my side, I just told her to schedule me for the next available in person appointment.  She had to cancel my appointment and then rebook it as their sub-standard system wouldn&amp;#39;t let her reschedule an at home appointment to at a location.  Surprisingly, she said they would refund my money and rebook me.  It was painless enough, but when I asked for a reference number on the refund, all she could do is say I &amp;#39;should&amp;#39; get an email.  Perhaps unsurprisingly, this morning I see a fully posted charge for the rescheduled exam, but no sign of a refund.  Sigh.  I will give it a few days and then start this process over.&lt;/p&gt;\n\n&lt;p&gt;For what its worth, people should IGNORE the advice that the web chat is the fastest way of getting help.  Find the phone number and dial and re-dial it as fast as you can when you get a busy signal.  Despite the fact that it took 20+ minutes to get the number to pickup (and was &amp;#39;waiting&amp;#39; 20 minutes less from the phones point of view) I got a faster response from someone on the phone.  Web based chat never picked up, even though I left it running during my entire phone conversation.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Update #2&lt;/em&gt;: It took two more days than the charge, but the refund did show up in the correct amount on my credit card.  I am actually quite surprised.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed6858be-322a-11e9-a3f1-0e996dbdbce4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "fscq7v", "is_robot_indexable": true, "report_reasons": null, "author": "VariousChallenge", "discussion_type": null, "num_comments": 65, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/fscq7v/psa_dont_take_remote_exams_offered_by_pearson_vue/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://www.reddit.com/r/aws/comments/fscq7v/psa_dont_take_remote_exams_offered_by_pearson_vue/", "subreddit_subscribers": 125608, "created_utc": 1585660596.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": " Setup: ASP.NET Core Web App on ECS\n\nWe are attempting to use an NLB to pass SSL all the way through to the host. So far, I've been able to get non SSL TCP to work over port 80, but when trying TLS over port 443 the health checks keep failing which is causing ECS to keep shutting down the Task.\n\nDo I need to do anything special with the ASP.NET Core app to allow this? When running it locally in Docker, both 80 and 443 work just fine. I'm assuming in that case it's a self signed cert. The Dockerfile does contain \"Expose 443\", which again, works locally, so I would've expected this to transfer the same to ECS.\n\nWithout any logs contain the reason as to why the healthchecks are failing, I flying blind right now and have no idea where to look. My assumption is that it's SSL related, but I'm not sure.", "author_fullname": "t2_avmmd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hard time getting TLS/SSL to work with Network Load Balancer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": true, "name": "t3_gyyf04", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "technical question", "can_mod_post": false, "score": 5, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591648169.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Setup: ASP.NET Core Web App on ECS&lt;/p&gt;\n\n&lt;p&gt;We are attempting to use an NLB to pass SSL all the way through to the host. So far, I&amp;#39;ve been able to get non SSL TCP to work over port 80, but when trying TLS over port 443 the health checks keep failing which is causing ECS to keep shutting down the Task.&lt;/p&gt;\n\n&lt;p&gt;Do I need to do anything special with the ASP.NET Core app to allow this? When running it locally in Docker, both 80 and 443 work just fine. I&amp;#39;m assuming in that case it&amp;#39;s a self signed cert. The Dockerfile does contain &amp;quot;Expose 443&amp;quot;, which again, works locally, so I would&amp;#39;ve expected this to transfer the same to ECS.&lt;/p&gt;\n\n&lt;p&gt;Without any logs contain the reason as to why the healthchecks are failing, I flying blind right now and have no idea where to look. My assumption is that it&amp;#39;s SSL related, but I&amp;#39;m not sure.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "e0acaab0-fe51-11e8-b457-0e86fa5111f4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gyyf04", "is_robot_indexable": true, "report_reasons": null, "author": "softwareguy74", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gyyf04/hard_time_getting_tlsssl_to_work_with_network/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gyyf04/hard_time_getting_tlsssl_to_work_with_network/", "subreddit_subscribers": 125608, "created_utc": 1591619369.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "Hi, I have a query, but want to be able to sort by the duration, which I am calculating as \"abs(start-end).\n\n&amp;#x200B;\n\n    fields @timestamp, dstPort, bytes, srcAddr, dstAddr, @message, abs(start-end)\n    | filter  dstPort = 80 and dstAddr = \"10.2.6.242\" \n    | sort @timestamp desc\n    | limit 2000\n\nHow can I do that? I had a play around with Parse but I don't think that is what I am looking for, but basically I think I want something like:\\~  \n\n\n    fields @timestamp, dstPort, bytes, srcAddr, dstAddr, @message, duration as abs(start-end)\n    | filter  dstPort = 80 and dstAddr = \"10.2.6.242\" \n    | sort duration desc\n    | limit 2000\n\nBut that doesn't work..\n\nAlso, does anyone know the standard size (in bytes) of an HTTP healthcheck from an NLB? I am seeing a lot of connections that are 164 bytes or 362 bytes so wondering if it is either of those? Or is it just not that easy?", "author_fullname": "t2_sma9u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Calculated field in Cloudwatch Log Insights", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_gyx7qf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "monitoring", "can_mod_post": false, "score": 3, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591642722.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have a query, but want to be able to sort by the duration, which I am calculating as &amp;quot;abs(start-end).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;fields @timestamp, dstPort, bytes, srcAddr, dstAddr, @message, abs(start-end)\n| filter  dstPort = 80 and dstAddr = &amp;quot;10.2.6.242&amp;quot; \n| sort @timestamp desc\n| limit 2000\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;How can I do that? I had a play around with Parse but I don&amp;#39;t think that is what I am looking for, but basically I think I want something like:~  &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;fields @timestamp, dstPort, bytes, srcAddr, dstAddr, @message, duration as abs(start-end)\n| filter  dstPort = 80 and dstAddr = &amp;quot;10.2.6.242&amp;quot; \n| sort duration desc\n| limit 2000\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;But that doesn&amp;#39;t work..&lt;/p&gt;\n\n&lt;p&gt;Also, does anyone know the standard size (in bytes) of an HTTP healthcheck from an NLB? I am seeing a lot of connections that are 164 bytes or 362 bytes so wondering if it is either of those? Or is it just not that easy?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "e6592206-1ce0-11e9-a9e6-0e7bd20fa500", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gyx7qf", "is_robot_indexable": true, "report_reasons": null, "author": "quarky_uk", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gyx7qf/calculated_field_in_cloudwatch_log_insights/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gyx7qf/calculated_field_in_cloudwatch_log_insights/", "subreddit_subscribers": 125608, "created_utc": 1591613922.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "Hi, \n\nI\u2019m relatively new to dotnet and trying to understand the benefits of a background service on Fargate (specifically .NET Core Worker Service)\n\nMy use case is that I want to query an RDS Database at 6pm everyday and check if a user has met specific conditions or not. If not, then send them a text.\n\nWould a .NET Worker Service running on Fargate be a good solution for this or having a lambda run at those times be a better approach?\n\nTrying to understand if a worker service would be an overkill for this use case. \n\nThank you.", "author_fullname": "t2_1njf6tih", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": ".Net Worker Service on Fargate vs Lambda", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_gyur6y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "architecture", "can_mod_post": false, "score": 5, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591630793.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, &lt;/p&gt;\n\n&lt;p&gt;I\u2019m relatively new to dotnet and trying to understand the benefits of a background service on Fargate (specifically .NET Core Worker Service)&lt;/p&gt;\n\n&lt;p&gt;My use case is that I want to query an RDS Database at 6pm everyday and check if a user has met specific conditions or not. If not, then send them a text.&lt;/p&gt;\n\n&lt;p&gt;Would a .NET Worker Service running on Fargate be a good solution for this or having a lambda run at those times be a better approach?&lt;/p&gt;\n\n&lt;p&gt;Trying to understand if a worker service would be an overkill for this use case. &lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "e18cf822-8ae6-11ea-8e8b-0edbae04a5bd", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "gyur6y", "is_robot_indexable": true, "report_reasons": null, "author": "infoboistandard", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gyur6y/net_worker_service_on_fargate_vs_lambda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gyur6y/net_worker_service_on_fargate_vs_lambda/", "subreddit_subscribers": 125608, "created_utc": 1591601993.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "This post is to see if the AWS solution I came up with is reasonable and see if anyone suggests alternatives:\n\nThe goal is to gather and save traffic data from here.com's api every few minutes.  It's to collect sample data for analysis tool -- and to get familiarity with some AWS tools.  It's not mission-critcal.\n\nHere.com uses a bearer token setup -- you authenticate with oauth secret keys, and get an access token that goes in request headers, the token expires in 24 hours.  \n\nI set up:\n  * two lambda functions, refresh-token and save-traffic-stats\n  * three ssm parameters: oauth-id, oauth-secret, and bearer-token, all SecureString\n\nEvery 10 hour refresh-token, using the oauth parms,  updates the bearer-token parm (thinking odds are it'll never be down, but if there's some transient error it'll probably be better in ten hours)\n\nEvery few minutes save-traffic-stats runs, reads the bearer token, gets the traffic data, and saves to s3.\n\nThe functions are scheduled with CloudWatch fixed rate event rules.\n\nIs that a reasonable/typical solution for this goal?\n\nOther thoughts... \n\nI read that if you were doing a lot of traffic, the ssm Parameter Store standard tier might throttle you -- the limits are so far beyond what I'm doing that's of no concern for me.\n\nFor this application it's not clear to me that it's any easier, more flexible, or more secure than running scripts by cron/at on an ec2 host.  I did hit one complication: I'm using python and the popular \"request\" http library is deprecated, so I had to fall back to comes-with-python urllib.\n\nThe setup so far has been  entirely thru the AWS Console and ad-hoc cli scripts.  My next goal is to set up terraform or similar to make the set up paramaterized/recreatable.", "author_fullname": "t2_hz3c9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS newbie -- setting up periodic data collection with lambda functions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_gyqq3s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "serverless", "can_mod_post": false, "score": 14, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591614363.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This post is to see if the AWS solution I came up with is reasonable and see if anyone suggests alternatives:&lt;/p&gt;\n\n&lt;p&gt;The goal is to gather and save traffic data from here.com&amp;#39;s api every few minutes.  It&amp;#39;s to collect sample data for analysis tool -- and to get familiarity with some AWS tools.  It&amp;#39;s not mission-critcal.&lt;/p&gt;\n\n&lt;p&gt;Here.com uses a bearer token setup -- you authenticate with oauth secret keys, and get an access token that goes in request headers, the token expires in 24 hours.  &lt;/p&gt;\n\n&lt;p&gt;I set up:\n  * two lambda functions, refresh-token and save-traffic-stats\n  * three ssm parameters: oauth-id, oauth-secret, and bearer-token, all SecureString&lt;/p&gt;\n\n&lt;p&gt;Every 10 hour refresh-token, using the oauth parms,  updates the bearer-token parm (thinking odds are it&amp;#39;ll never be down, but if there&amp;#39;s some transient error it&amp;#39;ll probably be better in ten hours)&lt;/p&gt;\n\n&lt;p&gt;Every few minutes save-traffic-stats runs, reads the bearer token, gets the traffic data, and saves to s3.&lt;/p&gt;\n\n&lt;p&gt;The functions are scheduled with CloudWatch fixed rate event rules.&lt;/p&gt;\n\n&lt;p&gt;Is that a reasonable/typical solution for this goal?&lt;/p&gt;\n\n&lt;p&gt;Other thoughts... &lt;/p&gt;\n\n&lt;p&gt;I read that if you were doing a lot of traffic, the ssm Parameter Store standard tier might throttle you -- the limits are so far beyond what I&amp;#39;m doing that&amp;#39;s of no concern for me.&lt;/p&gt;\n\n&lt;p&gt;For this application it&amp;#39;s not clear to me that it&amp;#39;s any easier, more flexible, or more secure than running scripts by cron/at on an ec2 host.  I did hit one complication: I&amp;#39;m using python and the popular &amp;quot;request&amp;quot; http library is deprecated, so I had to fall back to comes-with-python urllib.&lt;/p&gt;\n\n&lt;p&gt;The setup so far has been  entirely thru the AWS Console and ad-hoc cli scripts.  My next goal is to set up terraform or similar to make the set up paramaterized/recreatable.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ff0e4f90-fe51-11e8-995f-0e494176cf40", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gyqq3s", "is_robot_indexable": true, "report_reasons": null, "author": "Earthsophagus", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gyqq3s/aws_newbie_setting_up_periodic_data_collection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gyqq3s/aws_newbie_setting_up_periodic_data_collection/", "subreddit_subscribers": 125608, "created_utc": 1591585563.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "Very frustrating because I have come to rely on this sub for timely help and now o have to wait for a moderator to approve.  Why is that now?  None of the other subs I frequent require that.", "author_fullname": "t2_avmmd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why are all new posts pending moderator review now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": true, "name": "t3_gyy4a2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "discussion", "can_mod_post": false, "score": 2, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591646891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Very frustrating because I have come to rely on this sub for timely help and now o have to wait for a moderator to approve.  Why is that now?  None of the other subs I frequent require that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "962d796e-fa9c-11e8-a3dc-0e1ba4fe1be4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gyy4a2", "is_robot_indexable": true, "report_reasons": null, "author": "softwareguy74", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gyy4a2/why_are_all_new_posts_pending_moderator_review_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gyy4a2/why_are_all_new_posts_pending_moderator_review_now/", "subreddit_subscribers": 125608, "created_utc": 1591618091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "", "author_fullname": "t2_5ggm5svc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Slack\u2019s new integration deal with AWS could also be about tweaking Microsoft", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_gyiq2i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "discussion", "can_mod_post": false, "score": 32, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1591587162.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "techcrunch.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "962d796e-fa9c-11e8-a3dc-0e1ba4fe1be4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gyiq2i", "is_robot_indexable": true, "report_reasons": null, "author": "awsconsultant", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gyiq2i/slacks_new_integration_deal_with_aws_could_also/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://techcrunch.com/2020/06/05/slacks-new-integration-deal-with-aws-could-also-be-about-tweaking-microsoft/", "subreddit_subscribers": 125608, "created_utc": 1591558362.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "I have a REST API that's using Lambda as the \"backend\". My boss hired a third party VA/PT engineer to check the configuration of the application and then I got a report that I should be enabling API gateway's client certificate to let my back end know that requests are coming from API Gateway. \n\nNow please take note that I'm fairly new to AWS services (or security, for that matter) and from what I know AWS already requires API gateway to have \"permissions\" before it can access lambda. From that, I assume Lambda would already know that requests come from API gateway. \n\nMy question is should I enable API gateway's client certificate when connecting to Lambda? and if so, how do I do that?", "author_fullname": "t2_2cdy230y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "question on API gateway client certificate", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_gyuvcm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "general aws", "can_mod_post": false, "score": 3, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591631292.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a REST API that&amp;#39;s using Lambda as the &amp;quot;backend&amp;quot;. My boss hired a third party VA/PT engineer to check the configuration of the application and then I got a report that I should be enabling API gateway&amp;#39;s client certificate to let my back end know that requests are coming from API Gateway. &lt;/p&gt;\n\n&lt;p&gt;Now please take note that I&amp;#39;m fairly new to AWS services (or security, for that matter) and from what I know AWS already requires API gateway to have &amp;quot;permissions&amp;quot; before it can access lambda. From that, I assume Lambda would already know that requests come from API gateway. &lt;/p&gt;\n\n&lt;p&gt;My question is should I enable API gateway&amp;#39;s client certificate when connecting to Lambda? and if so, how do I do that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "256aecca-fe52-11e8-bc65-0eea6867f0e4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gyuvcm", "is_robot_indexable": true, "report_reasons": null, "author": "uchisasori", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gyuvcm/question_on_api_gateway_client_certificate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gyuvcm/question_on_api_gateway_client_certificate/", "subreddit_subscribers": 125608, "created_utc": 1591602492.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "So we have lot of database and pub/sub server such as Kafka and Cassandra in dev and production in our start up. Amazon notified us our instance type are t2-3, m1 and m3 and they need to be migrated to the latest gen which is m5 I believe.The story with them is that AWS is considering the underlying type oh hardware as obsolete and more failure prone than their best availability standards. My question is how do I achieve this. Do I have to snapshot this first and deploy new instance ? Never migrated instances before so curious on how to do this safely ?\n\nTLDR: Need to migrate old gen instance to the latest gen. How do I achieve in the best secure way without losing data and minimal downtime and outage. ", "author_fullname": "t2_1ep6xzfi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrating old instance type to the latest gen question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": true, "name": "t3_gyz5hy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "technical question", "can_mod_post": false, "score": 1, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": 1591622541.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591651047.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So we have lot of database and pub/sub server such as Kafka and Cassandra in dev and production in our start up. Amazon notified us our instance type are t2-3, m1 and m3 and they need to be migrated to the latest gen which is m5 I believe.The story with them is that AWS is considering the underlying type oh hardware as obsolete and more failure prone than their best availability standards. My question is how do I achieve this. Do I have to snapshot this first and deploy new instance ? Never migrated instances before so curious on how to do this safely ?&lt;/p&gt;\n\n&lt;p&gt;TLDR: Need to migrate old gen instance to the latest gen. How do I achieve in the best secure way without losing data and minimal downtime and outage. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "e0acaab0-fe51-11e8-b457-0e86fa5111f4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gyz5hy", "is_robot_indexable": true, "report_reasons": null, "author": "Beast-UltraJ", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gyz5hy/migrating_old_instance_type_to_the_latest_gen/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gyz5hy/migrating_old_instance_type_to_the_latest_gen/", "subreddit_subscribers": 125608, "created_utc": 1591622247.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "Hi,\n\nwe need to AMI backup a production server. we are worried that there will be interruption doing so.  \nwe don't want interruption, as the server is online to serve clients.", "author_fullname": "t2_3k9uwpxy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would there be any interruption, when doing an AMI backup to a production server?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_gyuhou", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "technical question", "can_mod_post": false, "score": 2, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591629696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;we need to AMI backup a production server. we are worried that there will be interruption doing so.&lt;br/&gt;\nwe don&amp;#39;t want interruption, as the server is online to serve clients.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "e0acaab0-fe51-11e8-b457-0e86fa5111f4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gyuhou", "is_robot_indexable": true, "report_reasons": null, "author": "cysronald", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gyuhou/would_there_be_any_interruption_when_doing_an_ami/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gyuhou/would_there_be_any_interruption_when_doing_an_ami/", "subreddit_subscribers": 125608, "created_utc": 1591600896.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "I have hosted my PHP MySQL web application on EC-2 on windows 2019 on free tier. I have assigned the elastic IP to the instance and pointed to the our domain which is hosted on third party. Now i would like to enable the Free SSL certificate by amazon certificate manager and i have created that. I am little bit confused in the next steps can anyone help me there.\n\n1. Do i need to use Amazon Route 53 service for this? Is this service is available in free tier? Do i need to create an hosted zone in Route 53 with the domain name and create records and update these records into my third party domain provider portal? Is this step is really required in the free SSL setup to work on my domain?\n2. Or Elastic Load Balancer is the only one i need to set up in the further process to work the SSL?\n\nCan anyone advise me here and it will be really appreciated.\n\nThanks in advance!", "author_fullname": "t2_4w6xgy0n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Configuring Free SSL certificate on IIS in EC-2 Instance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_gyus2h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "compute", "can_mod_post": false, "score": 1, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": 1591603757.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591630899.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have hosted my PHP MySQL web application on EC-2 on windows 2019 on free tier. I have assigned the elastic IP to the instance and pointed to the our domain which is hosted on third party. Now i would like to enable the Free SSL certificate by amazon certificate manager and i have created that. I am little bit confused in the next steps can anyone help me there.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Do i need to use Amazon Route 53 service for this? Is this service is available in free tier? Do i need to create an hosted zone in Route 53 with the domain name and create records and update these records into my third party domain provider portal? Is this step is really required in the free SSL setup to work on my domain?&lt;/li&gt;\n&lt;li&gt;Or Elastic Load Balancer is the only one i need to set up in the further process to work the SSL?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Can anyone advise me here and it will be really appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d0114800-fe51-11e8-8d95-0e6b6816ccc4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gyus2h", "is_robot_indexable": true, "report_reasons": null, "author": "harsheena", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gyus2h/configuring_free_ssl_certificate_on_iis_in_ec2/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gyus2h/configuring_free_ssl_certificate_on_iis_in_ec2/", "subreddit_subscribers": 125608, "created_utc": 1591602099.0, "num_crossposts": 0, "media": null, "is_video": false}}], "after": "t3_gyus2h", "before": null}}