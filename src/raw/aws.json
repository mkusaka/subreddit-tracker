{"kind": "Listing", "data": {"modhash": "", "dist": 11, "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "I can't describe how horrible this experience was.  I am not looking forward to how much work I am going to have to do to get my money back.  This is not my first AWS certification (I have SA Pro and DevOps Pro), but is my first online exam.  The short version is: Don't take AWS exams via the Pearson Vue at home option, even if it is offered.  AWS should not be offering this option as I can attest it is a waste of time.  Ironically, AWS would have us use their services because of their high availability and scaling but apparently they don't ask their test partners to do the same!\n\nIt started off easy enough: I passed the initial 'checks' as it confirmed my internet speed, camera access, and microphone access.  I started the process 15+ minutes before my scheduled exam time.  I was able to open the app, it again verified the technical requirements passed, and I went to the next screen.  It asked for my cell phone number and texted me a link which opened a web page which requested to take my photo.  Easy enough.  I did that and then the web page went to 'Uploading and verifying photo'.  A spinning circle started spinning.  This is where my test experience ended, but not where the poor experience ends.  I tried again, and then a third time.  Same experience.  As I write this, I left it on that page and the spinning is continuing.  This screen has been spinning for no less than 45 minutes.  At 8 minutes before my scheduled exam, I tried finding the help link.  A chat window opened, and I waited, and waited, and waited.  Still waiting as I write this.  My chat window has been open for 52 minutes and still no one to help.  Every two minutes I get ' All agents are currently assisting others. Thank you for your patience.' written in the window.  OK - what next?  They make it harder to find, but I got a phone number I can call.  I tried calling that.  Busy signal.  For the next 20 minutes I called back and back, busy signal.  Finally, I got it to actually pick up, but of course no human yet.  No estimate of time to when I can be helped.  They don't even have nice elevator music to listen to.  Who knows when I will be able to talk to someone.  This has been an exceedingly poor experience.\n\nIf you value your time, please do yourself a favor and don't even attempt a online exam with Pearson.  I worked hard to prepare for this exam and rescheduled things to fit around it.  Now, I will have to do that all again.\n\nu/jeffbarr Is this the experience AWS is hoping to get with their testing partners?  This was a waste of my time and money.  Amazon should seriously reevaluate the quality of their test partners.  I understand everyone is trying to deal with all the issues.  However, if you can't offer quality testing, then please don't offer the option at all.  It isn't respectful to people's time.  Pearson is well aware of their capacity and if it isn't up to requirements, they shouldn't be scheduling test slots.\n\n&amp;#x200B;\n\n*EDIT*: A few background items I didn't initially share that may be relevant for others.  For the computer, I used a fully up to date Windows 10 laptop.  The laptop itself is only about a month old and is in near pristine condition.  Other than a few applications like Office, there is barely anything installed on there yet.  I used a hard wired connection, like recommended by Pearson through the use of a usb-to-ethernet adapter.  I have Verizon FIOS (980Mbps/840Mbps) and did do a speed test way after it was apparent this would not work.  I forget the exact numbers, but I was still pulling in hundreds of Mbps in both directions, despite everyone being at home and using the USB ethernet adapater which does put a cap on my speed, but I can't see hundreds of Mbps not being sufficent by orders of magnatude.  My phone is a fully up to date pixel 3.  I tried using my wifi in my house first (connected through FIOS), and then using the phone 4G LTE connection.  I can't imagine this was caused by my end.  It seemed like Pearson's servers were jammed at that point in time.\n\n&amp;#x200B;\n\n*Update*: After a LONG time, I did eventually get someone to answer from Pearson.  They were nice enough and were fairly easy to understand, although there was an delay echo introduced where whatever I said was echoed a quarter to half second later which was annoying, but bearable.  I was just happy she was able to hear me.  She said she could open a trouble ticket for me, but as it was well over an hour trying to get through to any human and doubtful it was on my side, I just told her to schedule me for the next available in person appointment.  She had to cancel my appointment and then rebook it as their sub-standard system wouldn't let her reschedule an at home appointment to at a location.  Surprisingly, she said they would refund my money and rebook me.  It was painless enough, but when I asked for a reference number on the refund, all she could do is say I 'should' get an email.  Perhaps unsurprisingly, this morning I see a fully posted charge for the rescheduled exam, but no sign of a refund.  Sigh.  I will give it a few days and then start this process over.\n\nFor what its worth, people should IGNORE the advice that the web chat is the fastest way of getting help.  Find the phone number and dial and re-dial it as fast as you can when you get a busy signal.  Despite the fact that it took 20+ minutes to get the number to pickup (and was 'waiting' 20 minutes less from the phones point of view) I got a faster response from someone on the phone.  Web based chat never picked up, even though I left it running during my entire phone conversation.\n\n*Update #2*: It took two more days than the charge, but the refund did show up in the correct amount on my credit card.  I am actually quite surprised.", "author_fullname": "t2_43vca68k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PSA: Don't take remote exams offered by Pearson Vue (OnVue) for AWS Certifications!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_fscq7v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 60, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "training/certification", "can_mod_post": false, "score": 60, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": 1585824763.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1585689396.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I can&amp;#39;t describe how horrible this experience was.  I am not looking forward to how much work I am going to have to do to get my money back.  This is not my first AWS certification (I have SA Pro and DevOps Pro), but is my first online exam.  The short version is: Don&amp;#39;t take AWS exams via the Pearson Vue at home option, even if it is offered.  AWS should not be offering this option as I can attest it is a waste of time.  Ironically, AWS would have us use their services because of their high availability and scaling but apparently they don&amp;#39;t ask their test partners to do the same!&lt;/p&gt;\n\n&lt;p&gt;It started off easy enough: I passed the initial &amp;#39;checks&amp;#39; as it confirmed my internet speed, camera access, and microphone access.  I started the process 15+ minutes before my scheduled exam time.  I was able to open the app, it again verified the technical requirements passed, and I went to the next screen.  It asked for my cell phone number and texted me a link which opened a web page which requested to take my photo.  Easy enough.  I did that and then the web page went to &amp;#39;Uploading and verifying photo&amp;#39;.  A spinning circle started spinning.  This is where my test experience ended, but not where the poor experience ends.  I tried again, and then a third time.  Same experience.  As I write this, I left it on that page and the spinning is continuing.  This screen has been spinning for no less than 45 minutes.  At 8 minutes before my scheduled exam, I tried finding the help link.  A chat window opened, and I waited, and waited, and waited.  Still waiting as I write this.  My chat window has been open for 52 minutes and still no one to help.  Every two minutes I get &amp;#39; All agents are currently assisting others. Thank you for your patience.&amp;#39; written in the window.  OK - what next?  They make it harder to find, but I got a phone number I can call.  I tried calling that.  Busy signal.  For the next 20 minutes I called back and back, busy signal.  Finally, I got it to actually pick up, but of course no human yet.  No estimate of time to when I can be helped.  They don&amp;#39;t even have nice elevator music to listen to.  Who knows when I will be able to talk to someone.  This has been an exceedingly poor experience.&lt;/p&gt;\n\n&lt;p&gt;If you value your time, please do yourself a favor and don&amp;#39;t even attempt a online exam with Pearson.  I worked hard to prepare for this exam and rescheduled things to fit around it.  Now, I will have to do that all again.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"/u/jeffbarr\"&gt;u/jeffbarr&lt;/a&gt; Is this the experience AWS is hoping to get with their testing partners?  This was a waste of my time and money.  Amazon should seriously reevaluate the quality of their test partners.  I understand everyone is trying to deal with all the issues.  However, if you can&amp;#39;t offer quality testing, then please don&amp;#39;t offer the option at all.  It isn&amp;#39;t respectful to people&amp;#39;s time.  Pearson is well aware of their capacity and if it isn&amp;#39;t up to requirements, they shouldn&amp;#39;t be scheduling test slots.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;EDIT&lt;/em&gt;: A few background items I didn&amp;#39;t initially share that may be relevant for others.  For the computer, I used a fully up to date Windows 10 laptop.  The laptop itself is only about a month old and is in near pristine condition.  Other than a few applications like Office, there is barely anything installed on there yet.  I used a hard wired connection, like recommended by Pearson through the use of a usb-to-ethernet adapter.  I have Verizon FIOS (980Mbps/840Mbps) and did do a speed test way after it was apparent this would not work.  I forget the exact numbers, but I was still pulling in hundreds of Mbps in both directions, despite everyone being at home and using the USB ethernet adapater which does put a cap on my speed, but I can&amp;#39;t see hundreds of Mbps not being sufficent by orders of magnatude.  My phone is a fully up to date pixel 3.  I tried using my wifi in my house first (connected through FIOS), and then using the phone 4G LTE connection.  I can&amp;#39;t imagine this was caused by my end.  It seemed like Pearson&amp;#39;s servers were jammed at that point in time.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Update&lt;/em&gt;: After a LONG time, I did eventually get someone to answer from Pearson.  They were nice enough and were fairly easy to understand, although there was an delay echo introduced where whatever I said was echoed a quarter to half second later which was annoying, but bearable.  I was just happy she was able to hear me.  She said she could open a trouble ticket for me, but as it was well over an hour trying to get through to any human and doubtful it was on my side, I just told her to schedule me for the next available in person appointment.  She had to cancel my appointment and then rebook it as their sub-standard system wouldn&amp;#39;t let her reschedule an at home appointment to at a location.  Surprisingly, she said they would refund my money and rebook me.  It was painless enough, but when I asked for a reference number on the refund, all she could do is say I &amp;#39;should&amp;#39; get an email.  Perhaps unsurprisingly, this morning I see a fully posted charge for the rescheduled exam, but no sign of a refund.  Sigh.  I will give it a few days and then start this process over.&lt;/p&gt;\n\n&lt;p&gt;For what its worth, people should IGNORE the advice that the web chat is the fastest way of getting help.  Find the phone number and dial and re-dial it as fast as you can when you get a busy signal.  Despite the fact that it took 20+ minutes to get the number to pickup (and was &amp;#39;waiting&amp;#39; 20 minutes less from the phones point of view) I got a faster response from someone on the phone.  Web based chat never picked up, even though I left it running during my entire phone conversation.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Update #2&lt;/em&gt;: It took two more days than the charge, but the refund did show up in the correct amount on my credit card.  I am actually quite surprised.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed6858be-322a-11e9-a3f1-0e996dbdbce4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "fscq7v", "is_robot_indexable": true, "report_reasons": null, "author": "VariousChallenge", "discussion_type": null, "num_comments": 57, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/fscq7v/psa_dont_take_remote_exams_offered_by_pearson_vue/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://www.reddit.com/r/aws/comments/fscq7v/psa_dont_take_remote_exams_offered_by_pearson_vue/", "subreddit_subscribers": 125092, "created_utc": 1585660596.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "", "author_fullname": "t2_ho9zq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I've created a tool - spotcost.net The one-pager about all spot instances information. It helps find the cheapest region/az, compare specs, regions, price in time and etc. The difference between regions is huge (10-300% sic!). What do you think?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": true, "name": "t3_gwgdkm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "general aws", "can_mod_post": false, "score": 9, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1591301995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "spotcost.net", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "256aecca-fe52-11e8-bc65-0eea6867f0e4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gwgdkm", "is_robot_indexable": true, "report_reasons": null, "author": "Gaploid", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gwgdkm/ive_created_a_tool_spotcostnet_the_onepager_about/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://spotcost.net", "subreddit_subscribers": 125092, "created_utc": 1591273195.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "", "author_fullname": "t2_30p4mzl2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "TLS 1.2 to become the minimum for all AWS FIPS endpoints | Amazon Web Services", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_gw1a47", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 113, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "security", "can_mod_post": false, "score": 113, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1591242916.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "aws.amazon.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b921bc38-fe51-11e8-b892-0e32848ff0d0", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gw1a47", "is_robot_indexable": true, "report_reasons": null, "author": "Pavneet-sing", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gw1a47/tls_12_to_become_the_minimum_for_all_aws_fips/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://aws.amazon.com/blogs/security/tls-1-2-to-become-the-minimum-for-all-aws-fips-endpoints/", "subreddit_subscribers": 125092, "created_utc": 1591214116.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "Is there any reason for someone to use traditional CA certificates (Comodo/Digicert etc) if they are fully on AWS, and do not plan to install the certificates in EC2 ? How would you convince corporate IT teams that traditional CA signed certificates offer no additional value;  and ACM in fact removes a lot of head aches offered by them like cert rotation?\n\nEven if we decide to install certs on EC2, is there any advantage for paid certificates over those given by Lets Encrypt ?", "author_fullname": "t2_1wi63wmq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any reason NOT to use ACM Certificates ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_gw99u5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "discussion", "can_mod_post": false, "score": 13, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591269978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there any reason for someone to use traditional CA certificates (Comodo/Digicert etc) if they are fully on AWS, and do not plan to install the certificates in EC2 ? How would you convince corporate IT teams that traditional CA signed certificates offer no additional value;  and ACM in fact removes a lot of head aches offered by them like cert rotation?&lt;/p&gt;\n\n&lt;p&gt;Even if we decide to install certs on EC2, is there any advantage for paid certificates over those given by Lets Encrypt ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "962d796e-fa9c-11e8-a3dc-0e1ba4fe1be4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gw99u5", "is_robot_indexable": true, "report_reasons": null, "author": "the_screenslaver", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gw99u5/any_reason_not_to_use_acm_certificates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gw99u5/any_reason_not_to_use_acm_certificates/", "subreddit_subscribers": 125092, "created_utc": 1591241178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "Hello Everybody,\n\nI created this script a while ago and thought it might be useful for people here who use RDS for MS SQL and want to either migrate their databases or back them up.\n\n&amp;#x200B;\n\nThis script iterates over all the databases except: master, model, rdsadmin, tmpdb, msdb.\n\n&amp;#x200B;\n\nprints the database name, and then backs it up as &lt;database\\_name&gt;.bak to s3 (make sure to change the arn of the s3 bucket.)\n\n&amp;#x200B;\n\n \n\n`DECLARE @value VARCHAR(50)`\n\n`DECLARE db_cursor CURSOR FOR`  \n\n`SELECT name FROM master.dbo.sysdatabases`\n\n`where name not in ('master','model','rdsadmin','tempdb','msdb')`\n\n`OPEN db_cursor`   \n\n`FETCH NEXT FROM db_cursor INTO @value`   \n\n`WHILE @@FETCH_STATUS = 0`   \n\n`BEGIN`   \n\n`PRINT @value`\n\n  `declare  @s3 nvarchar(MAX) = N'arn:aws:s3:::bucket_name/'+@value+'.BAK'`\n\n  `exec msdb.dbo.rds_backup_database` \n\n`@source_db_name=@value,`\n\n`@s3_arn_to_backup_to=@s3,` \n\n`@overwrite_S3_backup_file=1;`\n\n`FETCH NEXT FROM db_cursor INTO @value`   \n\n`END`   \n\n`CLOSE db_cursor`   \n\n`DEALLOCATE db_cursor`\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nHopefully this helps someone!", "author_fullname": "t2_12u0ve", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RDS Script - Iterating over MS SQL databases and backing them up to s3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_gwealg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "database", "can_mod_post": false, "score": 6, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591292513.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everybody,&lt;/p&gt;\n\n&lt;p&gt;I created this script a while ago and thought it might be useful for people here who use RDS for MS SQL and want to either migrate their databases or back them up.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;This script iterates over all the databases except: master, model, rdsadmin, tmpdb, msdb.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;prints the database name, and then backs it up as &amp;lt;database\\_name&amp;gt;.bak to s3 (make sure to change the arn of the s3 bucket.)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;DECLARE @value VARCHAR(50)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;DECLARE db_cursor CURSOR FOR&lt;/code&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;SELECT name FROM master.dbo.sysdatabases&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;where name not in (&amp;#39;master&amp;#39;,&amp;#39;model&amp;#39;,&amp;#39;rdsadmin&amp;#39;,&amp;#39;tempdb&amp;#39;,&amp;#39;msdb&amp;#39;)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;OPEN db_cursor&lt;/code&gt;   &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;FETCH NEXT FROM db_cursor INTO @value&lt;/code&gt;   &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;WHILE @@FETCH_STATUS = 0&lt;/code&gt;   &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;BEGIN&lt;/code&gt;   &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;PRINT @value&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;declare  @s3 nvarchar(MAX) = N&amp;#39;arn:aws:s3:::bucket_name/&amp;#39;+@value+&amp;#39;.BAK&amp;#39;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;exec msdb.dbo.rds_backup_database&lt;/code&gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;@source_db_name=@value,&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;@s3_arn_to_backup_to=@s3,&lt;/code&gt; &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;@overwrite_S3_backup_file=1;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;FETCH NEXT FROM db_cursor INTO @value&lt;/code&gt;   &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;END&lt;/code&gt;   &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;CLOSE db_cursor&lt;/code&gt;   &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;DEALLOCATE db_cursor&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Hopefully this helps someone!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "c67223e6-fe51-11e8-96e8-0e985e0a8712", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gwealg", "is_robot_indexable": true, "report_reasons": null, "author": "derdlok", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gwealg/rds_script_iterating_over_ms_sql_databases_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gwealg/rds_script_iterating_over_ms_sql_databases_and/", "subreddit_subscribers": 125092, "created_utc": 1591263713.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "We have setup that converts raw videos into HLS format (.m3u8 and .ts files) and organises them into a directory inside a s3 bucket. Each directory inside the bucket represents one video. Since s3 doesn't really have the concept of directory in its implementation, it does not allow us to get a signed url to read the content of the directory to feed into the video player.\n\nI tried signing the URL for the .m3u8 file alone with getObject, but since tries to fetch the parts of the video to play, it will be thrown with an 403 by s3. Using cloudfront is not an option for us at this stage.\n\nIs there a better and secure way to handle the streaming from s3 without making the entire bucket public?", "author_fullname": "t2_tt70jaq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Authorising HLS streaming files from Amazon S3 directory", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": true, "name": "t3_gwglv0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "technical question", "can_mod_post": false, "score": 2, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591302908.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have setup that converts raw videos into HLS format (.m3u8 and .ts files) and organises them into a directory inside a s3 bucket. Each directory inside the bucket represents one video. Since s3 doesn&amp;#39;t really have the concept of directory in its implementation, it does not allow us to get a signed url to read the content of the directory to feed into the video player.&lt;/p&gt;\n\n&lt;p&gt;I tried signing the URL for the .m3u8 file alone with getObject, but since tries to fetch the parts of the video to play, it will be thrown with an 403 by s3. Using cloudfront is not an option for us at this stage.&lt;/p&gt;\n\n&lt;p&gt;Is there a better and secure way to handle the streaming from s3 without making the entire bucket public?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "e0acaab0-fe51-11e8-b457-0e86fa5111f4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gwglv0", "is_robot_indexable": true, "report_reasons": null, "author": "vishwasnavadak", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gwglv0/authorising_hls_streaming_files_from_amazon_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gwglv0/authorising_hls_streaming_files_from_amazon_s3/", "subreddit_subscribers": 125092, "created_utc": 1591274108.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": " Hey!\n\nI love to use ALB in front of EC2 instances because then I don\u2019t need to worry about SSL on EC2 instances (on nginx side), but rather use ACM on ALB for 2 of my domains (site has to work on both [example1.com](http://example1.com/) and [example2.com](http://example2.com/), 2 certificates - [example2.com](http://example2.com/) is a CNAME to [example1.com](http://example1.com/), which right now is a CNAME to load balancer address). But is there a way of doing this when there\u2019s only 1 EC2 instance and I don\u2019t need ALB, but I still don\u2019t want to manage certificates on the EC2 side?\n\nThe reason I\u2019m asking is that I sometimes just need 1 instance, but sometimes I need to scale and need to add more EC2 instances and load balance them. The times I only need 1, I would rather not use the ALB to save money. Can I provision any sort of AWS resource that would serve as an entrypoint and would pass that request to the EC2 instance? I noticed CloudFront can be used to serve dynamic content as well, but it only supports 1 ACM certificate. Can API gateway be configured in such a way to pass the request down to EC2 instance but provide multiple certificates as well?  \n \n\nI would like to be as flexible as possible, where I would CNAME my domains to some endpoint that stands in front of EC2, then if I need more instances, I would provision ALB, add those instances and swap out the CNAME to ALB\u2019s address. I would love to hear out what you guys think.\n\nAll of this now works with ALB. I can just remove and add targeted instances, but in case I only need 1 instance, ALB is wasting money for my use case.\n\n&amp;#x200B;\n\nI'm not very experienced in AWS, so I would love to hear your opinions.", "author_fullname": "t2_vwbxn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "API entrypoint with ACM certificates without ALB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": true, "name": "t3_gwh45t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "technical question", "can_mod_post": false, "score": 1, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591304885.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey!&lt;/p&gt;\n\n&lt;p&gt;I love to use ALB in front of EC2 instances because then I don\u2019t need to worry about SSL on EC2 instances (on nginx side), but rather use ACM on ALB for 2 of my domains (site has to work on both &lt;a href=\"http://example1.com/\"&gt;example1.com&lt;/a&gt; and &lt;a href=\"http://example2.com/\"&gt;example2.com&lt;/a&gt;, 2 certificates - &lt;a href=\"http://example2.com/\"&gt;example2.com&lt;/a&gt; is a CNAME to &lt;a href=\"http://example1.com/\"&gt;example1.com&lt;/a&gt;, which right now is a CNAME to load balancer address). But is there a way of doing this when there\u2019s only 1 EC2 instance and I don\u2019t need ALB, but I still don\u2019t want to manage certificates on the EC2 side?&lt;/p&gt;\n\n&lt;p&gt;The reason I\u2019m asking is that I sometimes just need 1 instance, but sometimes I need to scale and need to add more EC2 instances and load balance them. The times I only need 1, I would rather not use the ALB to save money. Can I provision any sort of AWS resource that would serve as an entrypoint and would pass that request to the EC2 instance? I noticed CloudFront can be used to serve dynamic content as well, but it only supports 1 ACM certificate. Can API gateway be configured in such a way to pass the request down to EC2 instance but provide multiple certificates as well?  &lt;/p&gt;\n\n&lt;p&gt;I would like to be as flexible as possible, where I would CNAME my domains to some endpoint that stands in front of EC2, then if I need more instances, I would provision ALB, add those instances and swap out the CNAME to ALB\u2019s address. I would love to hear out what you guys think.&lt;/p&gt;\n\n&lt;p&gt;All of this now works with ALB. I can just remove and add targeted instances, but in case I only need 1 instance, ALB is wasting money for my use case.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not very experienced in AWS, so I would love to hear your opinions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "e0acaab0-fe51-11e8-b457-0e86fa5111f4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gwh45t", "is_robot_indexable": true, "report_reasons": null, "author": "crnkovic", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gwh45t/api_entrypoint_with_acm_certificates_without_alb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gwh45t/api_entrypoint_with_acm_certificates_without_alb/", "subreddit_subscribers": 125092, "created_utc": 1591276085.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "I purchased my domain name at Godaddy, then changed the nameservers in Godaddy's DNS settings over to my AWS nameservers. AWS now controls my DNS records so I added an A record and two CNAME records. \n\nThe A record points to my static IP (@.example.com --&gt; staticIP) and my CNAME records point to my domain name ([www.example.com](https://www.example.com) \\--&gt; [example.com](https://example.com))\n\nBoth my subdomains from the CNAME records take me to the correct website hosted on Lightsail, but going to the main domain ([example.com](https://example.com)) still takes me to Godaddy's website builder that I set up when I bought the domain. There are no other options in Godaddy's DNS settings except to transfer the domain which isn't available for another month. I'm not sure what else to do on the AWS side because I already set up the A record, but it's not working correctly. Anyone know what else I can do?", "author_fullname": "t2_5ox10", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Domain still going to Godaddy website after setting up NS records with A record and CNAME records on AWS Lightsail", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": true, "name": "t3_gwh3l1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "technical question", "can_mod_post": false, "score": 1, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591304822.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I purchased my domain name at Godaddy, then changed the nameservers in Godaddy&amp;#39;s DNS settings over to my AWS nameservers. AWS now controls my DNS records so I added an A record and two CNAME records. &lt;/p&gt;\n\n&lt;p&gt;The A record points to my static IP (@.example.com --&amp;gt; staticIP) and my CNAME records point to my domain name (&lt;a href=\"https://www.example.com\"&gt;www.example.com&lt;/a&gt; --&amp;gt; &lt;a href=\"https://example.com\"&gt;example.com&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;Both my subdomains from the CNAME records take me to the correct website hosted on Lightsail, but going to the main domain (&lt;a href=\"https://example.com\"&gt;example.com&lt;/a&gt;) still takes me to Godaddy&amp;#39;s website builder that I set up when I bought the domain. There are no other options in Godaddy&amp;#39;s DNS settings except to transfer the domain which isn&amp;#39;t available for another month. I&amp;#39;m not sure what else to do on the AWS side because I already set up the A record, but it&amp;#39;s not working correctly. Anyone know what else I can do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "e0acaab0-fe51-11e8-b457-0e86fa5111f4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gwh3l1", "is_robot_indexable": true, "report_reasons": null, "author": "ardikus", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gwh3l1/domain_still_going_to_godaddy_website_after/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gwh3l1/domain_still_going_to_godaddy_website_after/", "subreddit_subscribers": 125092, "created_utc": 1591276022.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "", "author_fullname": "t2_129kk1ja", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Different Deployment Types Of AWS Elastic Beanstalk", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "article", "downs": 0, "top_awarded_type": null, "hide_score": true, "name": "t3_gwgzy3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "article", "can_mod_post": false, "score": 1, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1591304443.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ibexlabs.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "85ab6b1a-b9e3-11e6-847a-0e8ffa087616", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gwgzy3", "is_robot_indexable": true, "report_reasons": null, "author": "inkedlj", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gwgzy3/different_deployment_types_of_aws_elastic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.ibexlabs.com/different-deployment-types-of-aws-elastic-beanstalk/", "subreddit_subscribers": 125092, "created_utc": 1591275643.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "I am using it (PostgreSql) only for developing purposes. So I want it to be open only on work hours. Is there a way of scheduling it?", "author_fullname": "t2_3lfz01bz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automating RDS Start and Stop", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_gw7doh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "technical question", "can_mod_post": false, "score": 7, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591262779.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am using it (PostgreSql) only for developing purposes. So I want it to be open only on work hours. Is there a way of scheduling it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "e0acaab0-fe51-11e8-b457-0e86fa5111f4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gw7doh", "is_robot_indexable": true, "report_reasons": null, "author": "mcan5432", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gw7doh/automating_rds_start_and_stop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gw7doh/automating_rds_start_and_stop/", "subreddit_subscribers": 125092, "created_utc": 1591233979.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "I am trying to create a custom domain name mapping to API Gateway. I followed the documentation and I have following things in place:\n\n* SSL Certificate from ACM\n* Entry for desired domain in Route 53 with routing set to API End point\n\nNow only step remaining is adding API mapping. When I try to add an API mapping it throws errors saying  `Unable to complete operation due to concurrent modification. Please try again later.` \n\nNot able to figure out how to resolve this. Looking for assistance for the same.", "author_fullname": "t2_o7ijq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unable to map API Gateway to custom domain name", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_gwfprg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "technical question", "can_mod_post": false, "score": 1, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591299182.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to create a custom domain name mapping to API Gateway. I followed the documentation and I have following things in place:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;SSL Certificate from ACM&lt;/li&gt;\n&lt;li&gt;Entry for desired domain in Route 53 with routing set to API End point&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Now only step remaining is adding API mapping. When I try to add an API mapping it throws errors saying  &lt;code&gt;Unable to complete operation due to concurrent modification. Please try again later.&lt;/code&gt; &lt;/p&gt;\n\n&lt;p&gt;Not able to figure out how to resolve this. Looking for assistance for the same.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "e0acaab0-fe51-11e8-b457-0e86fa5111f4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gwfprg", "is_robot_indexable": true, "report_reasons": null, "author": "praveentpt", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gwfprg/unable_to_map_api_gateway_to_custom_domain_name/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gwfprg/unable_to_map_api_gateway_to_custom_domain_name/", "subreddit_subscribers": 125092, "created_utc": 1591270382.0, "num_crossposts": 0, "media": null, "is_video": false}}], "after": "t3_gwfprg", "before": null}}