{"kind": "Listing", "data": {"modhash": "", "dist": 11, "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "I can't describe how horrible this experience was.  I am not looking forward to how much work I am going to have to do to get my money back.  This is not my first AWS certification (I have SA Pro and DevOps Pro), but is my first online exam.  The short version is: Don't take AWS exams via the Pearson Vue at home option, even if it is offered.  AWS should not be offering this option as I can attest it is a waste of time.  Ironically, AWS would have us use their services because of their high availability and scaling but apparently they don't ask their test partners to do the same!\n\nIt started off easy enough: I passed the initial 'checks' as it confirmed my internet speed, camera access, and microphone access.  I started the process 15+ minutes before my scheduled exam time.  I was able to open the app, it again verified the technical requirements passed, and I went to the next screen.  It asked for my cell phone number and texted me a link which opened a web page which requested to take my photo.  Easy enough.  I did that and then the web page went to 'Uploading and verifying photo'.  A spinning circle started spinning.  This is where my test experience ended, but not where the poor experience ends.  I tried again, and then a third time.  Same experience.  As I write this, I left it on that page and the spinning is continuing.  This screen has been spinning for no less than 45 minutes.  At 8 minutes before my scheduled exam, I tried finding the help link.  A chat window opened, and I waited, and waited, and waited.  Still waiting as I write this.  My chat window has been open for 52 minutes and still no one to help.  Every two minutes I get ' All agents are currently assisting others. Thank you for your patience.' written in the window.  OK - what next?  They make it harder to find, but I got a phone number I can call.  I tried calling that.  Busy signal.  For the next 20 minutes I called back and back, busy signal.  Finally, I got it to actually pick up, but of course no human yet.  No estimate of time to when I can be helped.  They don't even have nice elevator music to listen to.  Who knows when I will be able to talk to someone.  This has been an exceedingly poor experience.\n\nIf you value your time, please do yourself a favor and don't even attempt a online exam with Pearson.  I worked hard to prepare for this exam and rescheduled things to fit around it.  Now, I will have to do that all again.\n\nu/jeffbarr Is this the experience AWS is hoping to get with their testing partners?  This was a waste of my time and money.  Amazon should seriously reevaluate the quality of their test partners.  I understand everyone is trying to deal with all the issues.  However, if you can't offer quality testing, then please don't offer the option at all.  It isn't respectful to people's time.  Pearson is well aware of their capacity and if it isn't up to requirements, they shouldn't be scheduling test slots.\n\n&amp;#x200B;\n\n*EDIT*: A few background items I didn't initially share that may be relevant for others.  For the computer, I used a fully up to date Windows 10 laptop.  The laptop itself is only about a month old and is in near pristine condition.  Other than a few applications like Office, there is barely anything installed on there yet.  I used a hard wired connection, like recommended by Pearson through the use of a usb-to-ethernet adapter.  I have Verizon FIOS (980Mbps/840Mbps) and did do a speed test way after it was apparent this would not work.  I forget the exact numbers, but I was still pulling in hundreds of Mbps in both directions, despite everyone being at home and using the USB ethernet adapater which does put a cap on my speed, but I can't see hundreds of Mbps not being sufficent by orders of magnatude.  My phone is a fully up to date pixel 3.  I tried using my wifi in my house first (connected through FIOS), and then using the phone 4G LTE connection.  I can't imagine this was caused by my end.  It seemed like Pearson's servers were jammed at that point in time.\n\n&amp;#x200B;\n\n*Update*: After a LONG time, I did eventually get someone to answer from Pearson.  They were nice enough and were fairly easy to understand, although there was an delay echo introduced where whatever I said was echoed a quarter to half second later which was annoying, but bearable.  I was just happy she was able to hear me.  She said she could open a trouble ticket for me, but as it was well over an hour trying to get through to any human and doubtful it was on my side, I just told her to schedule me for the next available in person appointment.  She had to cancel my appointment and then rebook it as their sub-standard system wouldn't let her reschedule an at home appointment to at a location.  Surprisingly, she said they would refund my money and rebook me.  It was painless enough, but when I asked for a reference number on the refund, all she could do is say I 'should' get an email.  Perhaps unsurprisingly, this morning I see a fully posted charge for the rescheduled exam, but no sign of a refund.  Sigh.  I will give it a few days and then start this process over.\n\nFor what its worth, people should IGNORE the advice that the web chat is the fastest way of getting help.  Find the phone number and dial and re-dial it as fast as you can when you get a busy signal.  Despite the fact that it took 20+ minutes to get the number to pickup (and was 'waiting' 20 minutes less from the phones point of view) I got a faster response from someone on the phone.  Web based chat never picked up, even though I left it running during my entire phone conversation.\n\n*Update #2*: It took two more days than the charge, but the refund did show up in the correct amount on my credit card.  I am actually quite surprised.", "author_fullname": "t2_43vca68k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PSA: Don't take remote exams offered by Pearson Vue (OnVue) for AWS Certifications!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_fscq7v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 68, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "training/certification", "can_mod_post": false, "score": 68, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": 1585824763.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1585689396.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I can&amp;#39;t describe how horrible this experience was.  I am not looking forward to how much work I am going to have to do to get my money back.  This is not my first AWS certification (I have SA Pro and DevOps Pro), but is my first online exam.  The short version is: Don&amp;#39;t take AWS exams via the Pearson Vue at home option, even if it is offered.  AWS should not be offering this option as I can attest it is a waste of time.  Ironically, AWS would have us use their services because of their high availability and scaling but apparently they don&amp;#39;t ask their test partners to do the same!&lt;/p&gt;\n\n&lt;p&gt;It started off easy enough: I passed the initial &amp;#39;checks&amp;#39; as it confirmed my internet speed, camera access, and microphone access.  I started the process 15+ minutes before my scheduled exam time.  I was able to open the app, it again verified the technical requirements passed, and I went to the next screen.  It asked for my cell phone number and texted me a link which opened a web page which requested to take my photo.  Easy enough.  I did that and then the web page went to &amp;#39;Uploading and verifying photo&amp;#39;.  A spinning circle started spinning.  This is where my test experience ended, but not where the poor experience ends.  I tried again, and then a third time.  Same experience.  As I write this, I left it on that page and the spinning is continuing.  This screen has been spinning for no less than 45 minutes.  At 8 minutes before my scheduled exam, I tried finding the help link.  A chat window opened, and I waited, and waited, and waited.  Still waiting as I write this.  My chat window has been open for 52 minutes and still no one to help.  Every two minutes I get &amp;#39; All agents are currently assisting others. Thank you for your patience.&amp;#39; written in the window.  OK - what next?  They make it harder to find, but I got a phone number I can call.  I tried calling that.  Busy signal.  For the next 20 minutes I called back and back, busy signal.  Finally, I got it to actually pick up, but of course no human yet.  No estimate of time to when I can be helped.  They don&amp;#39;t even have nice elevator music to listen to.  Who knows when I will be able to talk to someone.  This has been an exceedingly poor experience.&lt;/p&gt;\n\n&lt;p&gt;If you value your time, please do yourself a favor and don&amp;#39;t even attempt a online exam with Pearson.  I worked hard to prepare for this exam and rescheduled things to fit around it.  Now, I will have to do that all again.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"/u/jeffbarr\"&gt;u/jeffbarr&lt;/a&gt; Is this the experience AWS is hoping to get with their testing partners?  This was a waste of my time and money.  Amazon should seriously reevaluate the quality of their test partners.  I understand everyone is trying to deal with all the issues.  However, if you can&amp;#39;t offer quality testing, then please don&amp;#39;t offer the option at all.  It isn&amp;#39;t respectful to people&amp;#39;s time.  Pearson is well aware of their capacity and if it isn&amp;#39;t up to requirements, they shouldn&amp;#39;t be scheduling test slots.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;EDIT&lt;/em&gt;: A few background items I didn&amp;#39;t initially share that may be relevant for others.  For the computer, I used a fully up to date Windows 10 laptop.  The laptop itself is only about a month old and is in near pristine condition.  Other than a few applications like Office, there is barely anything installed on there yet.  I used a hard wired connection, like recommended by Pearson through the use of a usb-to-ethernet adapter.  I have Verizon FIOS (980Mbps/840Mbps) and did do a speed test way after it was apparent this would not work.  I forget the exact numbers, but I was still pulling in hundreds of Mbps in both directions, despite everyone being at home and using the USB ethernet adapater which does put a cap on my speed, but I can&amp;#39;t see hundreds of Mbps not being sufficent by orders of magnatude.  My phone is a fully up to date pixel 3.  I tried using my wifi in my house first (connected through FIOS), and then using the phone 4G LTE connection.  I can&amp;#39;t imagine this was caused by my end.  It seemed like Pearson&amp;#39;s servers were jammed at that point in time.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Update&lt;/em&gt;: After a LONG time, I did eventually get someone to answer from Pearson.  They were nice enough and were fairly easy to understand, although there was an delay echo introduced where whatever I said was echoed a quarter to half second later which was annoying, but bearable.  I was just happy she was able to hear me.  She said she could open a trouble ticket for me, but as it was well over an hour trying to get through to any human and doubtful it was on my side, I just told her to schedule me for the next available in person appointment.  She had to cancel my appointment and then rebook it as their sub-standard system wouldn&amp;#39;t let her reschedule an at home appointment to at a location.  Surprisingly, she said they would refund my money and rebook me.  It was painless enough, but when I asked for a reference number on the refund, all she could do is say I &amp;#39;should&amp;#39; get an email.  Perhaps unsurprisingly, this morning I see a fully posted charge for the rescheduled exam, but no sign of a refund.  Sigh.  I will give it a few days and then start this process over.&lt;/p&gt;\n\n&lt;p&gt;For what its worth, people should IGNORE the advice that the web chat is the fastest way of getting help.  Find the phone number and dial and re-dial it as fast as you can when you get a busy signal.  Despite the fact that it took 20+ minutes to get the number to pickup (and was &amp;#39;waiting&amp;#39; 20 minutes less from the phones point of view) I got a faster response from someone on the phone.  Web based chat never picked up, even though I left it running during my entire phone conversation.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Update #2&lt;/em&gt;: It took two more days than the charge, but the refund did show up in the correct amount on my credit card.  I am actually quite surprised.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed6858be-322a-11e9-a3f1-0e996dbdbce4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "fscq7v", "is_robot_indexable": true, "report_reasons": null, "author": "VariousChallenge", "discussion_type": null, "num_comments": 65, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/fscq7v/psa_dont_take_remote_exams_offered_by_pearson_vue/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://www.reddit.com/r/aws/comments/fscq7v/psa_dont_take_remote_exams_offered_by_pearson_vue/", "subreddit_subscribers": 125726, "created_utc": 1585660596.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "Unfortunately this community has no shitpost flair, as I would mark it (as it kinda is a shitpost).\n\nI'm a fan of cloud solutions and abstracting the data center, but in many organizations the cost outweights the benefits of migrating. I've seen migrations that quadrupled the cost of ownership for infrastructure with no clear benefit. And the only viable explanation for such a move would be something I've called the \"Golf Factor\".\n\nSo what is Golf Factor? Pretty simple, it's the ability for CEO/CTO, to say that they too use \"The Cloud\" during meetings with other C*Os. \n\nHave you guys noticed such behaviour? Has it influenced the decision to move to cloud, if yes how?", "author_fullname": "t2_1ugc8lm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Golf Factor", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": true, "name": "t3_gzn0fv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "discussion", "can_mod_post": false, "score": 2, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591737637.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Unfortunately this community has no shitpost flair, as I would mark it (as it kinda is a shitpost).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a fan of cloud solutions and abstracting the data center, but in many organizations the cost outweights the benefits of migrating. I&amp;#39;ve seen migrations that quadrupled the cost of ownership for infrastructure with no clear benefit. And the only viable explanation for such a move would be something I&amp;#39;ve called the &amp;quot;Golf Factor&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;So what is Golf Factor? Pretty simple, it&amp;#39;s the ability for CEO/CTO, to say that they too use &amp;quot;The Cloud&amp;quot; during meetings with other C*Os. &lt;/p&gt;\n\n&lt;p&gt;Have you guys noticed such behaviour? Has it influenced the decision to move to cloud, if yes how?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "962d796e-fa9c-11e8-a3dc-0e1ba4fe1be4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gzn0fv", "is_robot_indexable": true, "report_reasons": null, "author": "UndestroyableMousse", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gzn0fv/golf_factor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gzn0fv/golf_factor/", "subreddit_subscribers": 125726, "created_utc": 1591708837.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "All things being equal, is NLB faster in serving up content from a web server?  The way it's marketed seems to be around increased performance, but NLB seems much more challenging to get working vs ALB.", "author_fullname": "t2_avmmd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any real performance difference between an ALB and a NLB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_gz3zax", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 56, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "technical question", "can_mod_post": false, "score": 56, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591666959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;All things being equal, is NLB faster in serving up content from a web server?  The way it&amp;#39;s marketed seems to be around increased performance, but NLB seems much more challenging to get working vs ALB.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "e0acaab0-fe51-11e8-b457-0e86fa5111f4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gz3zax", "is_robot_indexable": true, "report_reasons": null, "author": "softwareguy74", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gz3zax/is_there_any_real_performance_difference_between/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gz3zax/is_there_any_real_performance_difference_between/", "subreddit_subscribers": 125726, "created_utc": 1591638159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "Hi AWS experts, \n\nI have a fair bit of knowledge about the AWS ecosystem and have been using it hands-on for a couple of years. However today my team asked me to start using AWS Glue for data catalogging, and I'm not able to understand how that is going to make any difference to the business user. \n\nSome basic understanding or blog post can help me here. \n\nThanks in advance.", "author_fullname": "t2_6lxvgbyr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How will you explain AWS Glue to a 5 year old", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_gziddr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "discussion", "can_mod_post": false, "score": 4, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591716876.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi AWS experts, &lt;/p&gt;\n\n&lt;p&gt;I have a fair bit of knowledge about the AWS ecosystem and have been using it hands-on for a couple of years. However today my team asked me to start using AWS Glue for data catalogging, and I&amp;#39;m not able to understand how that is going to make any difference to the business user. &lt;/p&gt;\n\n&lt;p&gt;Some basic understanding or blog post can help me here. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "962d796e-fa9c-11e8-a3dc-0e1ba4fe1be4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gziddr", "is_robot_indexable": true, "report_reasons": null, "author": "piratedengineer", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gziddr/how_will_you_explain_aws_glue_to_a_5_year_old/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gziddr/how_will_you_explain_aws_glue_to_a_5_year_old/", "subreddit_subscribers": 125726, "created_utc": 1591688076.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "Hi!\n\nMy current process for training on EC2 is wildly inefficient, I do the following.\n\n1. Go to EC2 Console -&gt; Spot Requests\n\n2. Select AMI, usually some DLAMI. Then Select instance type, p3.2x usually, apply an IAM role to allow me to download/write to S3.\n\n3. Go to Filezilla and connect via SFTP. Navigate to some directory, usually /dev/shm and transfer my files (models, scripts, even data if it's not large).\n\n4. SSH into instance via cmd, go to /dev/shm. apt-get things I might need and open a tmux window (so that I can close terminal without ending training). I then activate whatever environment I want from the DLAMI. Then I pip install the 6 - 12 libraries I am using.\n\n5. Finally either download from S3 the data if it's large, or just start some scripts. Observe via terminal output, HTOP, nvidia-smi.\n\n6. Once training is done, either use Filezilla to transfer files locally or upload to S3.\n\n7. Close instance\n\nso which parts am I doing wildly wrong?\n\nI feel like number 2 can be automated using templates? I've never done that. I also feel like if I am installing the same libraries over and over I could make some type of bash script or something?\n\nI also feel like the way I am transferring data from and to S3 (I always look up on stackexchange some commands) seems wrong.\n\nAny tips are much appreciated!", "author_fullname": "t2_plesx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Newbie with a very inefficient EC2/S3 workflow for ML model training. Interested in ways to automate environment prep (libraries, file downloads, etc).", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_gzkf8m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ai/ml", "can_mod_post": false, "score": 2, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591726978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;My current process for training on EC2 is wildly inefficient, I do the following.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Go to EC2 Console -&amp;gt; Spot Requests&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Select AMI, usually some DLAMI. Then Select instance type, p3.2x usually, apply an IAM role to allow me to download/write to S3.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Go to Filezilla and connect via SFTP. Navigate to some directory, usually /dev/shm and transfer my files (models, scripts, even data if it&amp;#39;s not large).&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;SSH into instance via cmd, go to /dev/shm. apt-get things I might need and open a tmux window (so that I can close terminal without ending training). I then activate whatever environment I want from the DLAMI. Then I pip install the 6 - 12 libraries I am using.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Finally either download from S3 the data if it&amp;#39;s large, or just start some scripts. Observe via terminal output, HTOP, nvidia-smi.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Once training is done, either use Filezilla to transfer files locally or upload to S3.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Close instance&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;so which parts am I doing wildly wrong?&lt;/p&gt;\n\n&lt;p&gt;I feel like number 2 can be automated using templates? I&amp;#39;ve never done that. I also feel like if I am installing the same libraries over and over I could make some type of bash script or something?&lt;/p&gt;\n\n&lt;p&gt;I also feel like the way I am transferring data from and to S3 (I always look up on stackexchange some commands) seems wrong.&lt;/p&gt;\n\n&lt;p&gt;Any tips are much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d3a107f8-fe51-11e8-b888-0e1e1992c532", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gzkf8m", "is_robot_indexable": true, "report_reasons": null, "author": "TechySpecky", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gzkf8m/newbie_with_a_very_inefficient_ec2s3_workflow_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gzkf8m/newbie_with_a_very_inefficient_ec2s3_workflow_for/", "subreddit_subscribers": 125726, "created_utc": 1591698178.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "We are investigating how to restrict usage in an account. \n\nHas anyone tried to *lowering* a service quota instead of increasing it? Example: Service Quotas currently say we have a maximum of 640 on-demand vCPU for a region as a limit in EC2; what if if would want that to much lower?", "author_fullname": "t2_81nch", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lowering service quota instead of increasing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": true, "name": "t3_gzn4ky", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "general aws", "can_mod_post": false, "score": 1, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591738044.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are investigating how to restrict usage in an account. &lt;/p&gt;\n\n&lt;p&gt;Has anyone tried to &lt;em&gt;lowering&lt;/em&gt; a service quota instead of increasing it? Example: Service Quotas currently say we have a maximum of 640 on-demand vCPU for a region as a limit in EC2; what if if would want that to much lower?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "256aecca-fe52-11e8-bc65-0eea6867f0e4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gzn4ky", "is_robot_indexable": true, "report_reasons": null, "author": "otsu-swe", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gzn4ky/lowering_service_quota_instead_of_increasing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gzn4ky/lowering_service_quota_instead_of_increasing/", "subreddit_subscribers": 125726, "created_utc": 1591709244.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "Hi all, I recently delivered an online meetup about how to get started with Terraform in AWS - Link: https://www.youtube.com/watch?v=cBDmoC7QonA\n\nTopics\n- Why should I use infrastructure as code?\n- How Terraform works\n- How to create infrastructure with Terraform (Demo)\n\nYou should watch this meetup if ...\n- You heard about the concept of infrastructure as code (IaC) and you need a \"push\" to get familiar with it\n- You want to learn how to create your first infrastructure as code with Terraform from scratch\n- You create your cloud infrastructure (resources) for the dev environment, using the GUI, and you feel comfortable with what you're doing. Your manager is happy with your work, and now you need to apply the same infrastructure to the staging environment, this is where you get overwhelmed - \"I wish there was a way to copy-paste the infrastructure to staging, I will never be able to recreate what I've done in dev\"\n- You need to create a VPC, while following best practices (security, resilience, flexibility, etc.) and you wonder if there's any tool that can assist in doing so\n- You want to automate the process of deploying/modifying/destroying your infrastructure's resources", "author_fullname": "t2_3kett2ru", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting started with Terraform in AWS [YouTube Video]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "resource", "downs": 0, "top_awarded_type": null, "hide_score": true, "name": "t3_gzn4kk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "technical resource", "can_mod_post": false, "score": 1, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": 1591709583.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591738043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I recently delivered an online meetup about how to get started with Terraform in AWS - Link: &lt;a href=\"https://www.youtube.com/watch?v=cBDmoC7QonA\"&gt;https://www.youtube.com/watch?v=cBDmoC7QonA&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Topics\n- Why should I use infrastructure as code?\n- How Terraform works\n- How to create infrastructure with Terraform (Demo)&lt;/p&gt;\n\n&lt;p&gt;You should watch this meetup if ...\n- You heard about the concept of infrastructure as code (IaC) and you need a &amp;quot;push&amp;quot; to get familiar with it\n- You want to learn how to create your first infrastructure as code with Terraform from scratch\n- You create your cloud infrastructure (resources) for the dev environment, using the GUI, and you feel comfortable with what you&amp;#39;re doing. Your manager is happy with your work, and now you need to apply the same infrastructure to the staging environment, this is where you get overwhelmed - &amp;quot;I wish there was a way to copy-paste the infrastructure to staging, I will never be able to recreate what I&amp;#39;ve done in dev&amp;quot;\n- You need to create a VPC, while following best practices (security, resilience, flexibility, etc.) and you wonder if there&amp;#39;s any tool that can assist in doing so\n- You want to automate the process of deploying/modifying/destroying your infrastructure&amp;#39;s resources&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "90cdeee6-b9e3-11e6-8d35-0eabbe333632", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gzn4kk", "is_robot_indexable": true, "report_reasons": null, "author": "unfors19", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gzn4kk/getting_started_with_terraform_in_aws_youtube/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gzn4kk/getting_started_with_terraform_in_aws_youtube/", "subreddit_subscribers": 125726, "created_utc": 1591709243.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "Sorry if I used the wrong flair. I'm new to AWS EC2, but looking to get an instance to do memory intensive work.\n\nSome background: Want to work with a dataset, but it doesn't fit into memory on my personal computer. \n\nI'm worried about the charges I'll accumulate because I'm working with something unfamilar and I expect a lot of buggy code. I expect to spend more time debugging than actually running my code. \n\nIs there a workaround for this, did I misunderstand how the pricing works, or do I have to suck it up and deal with it?", "author_fullname": "t2_mdkpy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Basic Question on EC2 Pricing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": true, "name": "t3_gzlo9q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "general aws", "can_mod_post": false, "score": 1, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591732472.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry if I used the wrong flair. I&amp;#39;m new to AWS EC2, but looking to get an instance to do memory intensive work.&lt;/p&gt;\n\n&lt;p&gt;Some background: Want to work with a dataset, but it doesn&amp;#39;t fit into memory on my personal computer. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m worried about the charges I&amp;#39;ll accumulate because I&amp;#39;m working with something unfamilar and I expect a lot of buggy code. I expect to spend more time debugging than actually running my code. &lt;/p&gt;\n\n&lt;p&gt;Is there a workaround for this, did I misunderstand how the pricing works, or do I have to suck it up and deal with it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "256aecca-fe52-11e8-bc65-0eea6867f0e4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gzlo9q", "is_robot_indexable": true, "report_reasons": null, "author": "WaifuMasterRace", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gzlo9q/basic_question_on_ec2_pricing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gzlo9q/basic_question_on_ec2_pricing/", "subreddit_subscribers": 125726, "created_utc": 1591703672.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "I am working on a python script that will send a filtered list (written to csv) to S3 from Security Hub Insights. It's a paginated response and I want to pull only the filtered keys,values and I'm not sure how to reference the Value of AwsAccount ID (these are in the boto response in the get_findings call) in the Filters dict, if anyone could tell me what I'm missing I would appreciate it.\n\n\n    def paginate(method, **kwargs):\n          client = method.__self__\n          paginator = client.get_paginator(method.__name__)\n          for page in paginator.paginate(**kwargs).result_key_iters():\n              for result in page:\n                  yield result\n\n    def getSecurityHubFindings():\n        hub = boto3.client('securityhub')\n        for key in paginate(hub.get_findings, Filters=filters):\n        print(key)\n    filters = {\n      'AwsAccountId': [\n        {\n          'Value': 'string',\n          'Comparison': 'EQUALS'\n        }\n      ]", "author_fullname": "t2_49h53", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I apply a filter to a paginated boto3 response?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_gza6ck", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "technical question", "can_mod_post": false, "score": 9, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": 1591656891.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591685128.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on a python script that will send a filtered list (written to csv) to S3 from Security Hub Insights. It&amp;#39;s a paginated response and I want to pull only the filtered keys,values and I&amp;#39;m not sure how to reference the Value of AwsAccount ID (these are in the boto response in the get_findings call) in the Filters dict, if anyone could tell me what I&amp;#39;m missing I would appreciate it.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def paginate(method, **kwargs):\n      client = method.__self__\n      paginator = client.get_paginator(method.__name__)\n      for page in paginator.paginate(**kwargs).result_key_iters():\n          for result in page:\n              yield result\n\ndef getSecurityHubFindings():\n    hub = boto3.client(&amp;#39;securityhub&amp;#39;)\n    for key in paginate(hub.get_findings, Filters=filters):\n    print(key)\nfilters = {\n  &amp;#39;AwsAccountId&amp;#39;: [\n    {\n      &amp;#39;Value&amp;#39;: &amp;#39;string&amp;#39;,\n      &amp;#39;Comparison&amp;#39;: &amp;#39;EQUALS&amp;#39;\n    }\n  ]\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "e0acaab0-fe51-11e8-b457-0e86fa5111f4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gza6ck", "is_robot_indexable": true, "report_reasons": null, "author": "crapspakkle", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gza6ck/how_do_i_apply_a_filter_to_a_paginated_boto3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gza6ck/how_do_i_apply_a_filter_to_a_paginated_boto3/", "subreddit_subscribers": 125726, "created_utc": 1591656328.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "I am making an application where users should connect as follows:\n\n[cliente.com](https://cliente.com) \\-&gt; CNAME -&gt; [mysystem.com](https://mysystem.com)\n\n&amp;#x200B;\n\nI've done the test on Route53 but it gives error", "author_fullname": "t2_6mc0i7v4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I get the cloudfront to accept connections from multiple domains?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_gzkl2p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "architecture", "can_mod_post": false, "score": 1, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1591727736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am making an application where users should connect as follows:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://cliente.com\"&gt;cliente.com&lt;/a&gt; -&amp;gt; CNAME -&amp;gt; &lt;a href=\"https://mysystem.com\"&gt;mysystem.com&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve done the test on Route53 but it gives error&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "e18cf822-8ae6-11ea-8e8b-0edbae04a5bd", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "gzkl2p", "is_robot_indexable": true, "report_reasons": null, "author": "darlei-cordeiro", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gzkl2p/how_do_i_get_the_cloudfront_to_accept_connections/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/gzkl2p/how_do_i_get_the_cloudfront_to_accept_connections/", "subreddit_subscribers": 125726, "created_utc": 1591698936.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "", "author_fullname": "t2_ncegk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on Serverless in 2020: Mechanical Rock", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_gz8zfg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "serverless", "can_mod_post": false, "score": 8, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1591681565.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "mechanicalrock.github.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ff0e4f90-fe51-11e8-995f-0e494176cf40", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "gz8zfg", "is_robot_indexable": true, "report_reasons": null, "author": "rowanu", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/gz8zfg/thoughts_on_serverless_in_2020_mechanical_rock/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://mechanicalrock.github.io/2020/06/02/serverless-trends.html", "subreddit_subscribers": 125726, "created_utc": 1591652765.0, "num_crossposts": 0, "media": null, "is_video": false}}], "after": "t3_gz8zfg", "before": null}}