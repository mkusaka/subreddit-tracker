{"kind": "Listing", "data": {"modhash": "", "dist": 12, "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "", "author_fullname": "t2_47mn7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "re:Invent registration is now open", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_jkenu3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": "#d3d6da", "subreddit_type": "public", "ups": 136, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": "225be7c0-5301-11e8-8cd5-0e24e4204d68", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "general aws", "can_mod_post": false, "score": 136, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": "userflairAWSstaff", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1604021930.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "register.virtual.awsevents.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://register.virtual.awsevents.com/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "256aecca-fe52-11e8-bc65-0eea6867f0e4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "AWS employee", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "jkenu3", "is_robot_indexable": true, "report_reasons": null, "author": "ckilborn", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/aws/comments/jkenu3/reinvent_registration_is_now_open/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://register.virtual.awsevents.com/", "subreddit_subscribers": 146176, "created_utc": 1603993130.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "Share your learnings with the community", "author_fullname": "t2_47mn7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Week of Nov 9th - What have you learned recently about AWS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_jqya79", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": "#d3d6da", "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": "225be7c0-5301-11e8-8cd5-0e24e4204d68", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "discussion", "can_mod_post": false, "score": 30, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": "userflairAWSstaff", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1604959960.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Share your learnings with the community&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "962d796e-fa9c-11e8-a3dc-0e1ba4fe1be4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "AWS employee", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "jqya79", "is_robot_indexable": true, "report_reasons": null, "author": "ckilborn", "discussion_type": null, "num_comments": 60, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/aws/comments/jqya79/week_of_nov_9th_what_have_you_learned_recently/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://www.reddit.com/r/aws/comments/jqya79/week_of_nov_9th_what_have_you_learned_recently/", "subreddit_subscribers": 146176, "created_utc": 1604931160.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "I am trying to build in AWS a platform that covers multiple regions\n\nI will have users signing up in EU and signing up in US\n\nI will use AWS Cognito to handle user auth\n\n&amp;#x200B;\n\nMy question is: if I failover a region - how do we migrate users across to the nearest (lowest latency) available region?\n\n&amp;#x200B;\n\nI have a secondary question around S3 too:\n\nI am using route53 latency based routing to route API customer requests to the Lambda/ElasticSearch that is closest to them.  To do the same with S3 too means I must make our bucket public (not acceptable) - or only have the user write to one bucket (and authenticate with Cognito) but then the write latency will be very high\n\n&amp;#x200B;\n\nThanks for your time!", "author_fullname": "t2_ak5cz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Cognito Multi-Region Failover", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": true, "name": "t3_js6tmv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "technical question", "can_mod_post": false, "score": 5, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1605124493.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to build in AWS a platform that covers multiple regions&lt;/p&gt;\n\n&lt;p&gt;I will have users signing up in EU and signing up in US&lt;/p&gt;\n\n&lt;p&gt;I will use AWS Cognito to handle user auth&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My question is: if I failover a region - how do we migrate users across to the nearest (lowest latency) available region?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have a secondary question around S3 too:&lt;/p&gt;\n\n&lt;p&gt;I am using route53 latency based routing to route API customer requests to the Lambda/ElasticSearch that is closest to them.  To do the same with S3 too means I must make our bucket public (not acceptable) - or only have the user write to one bucket (and authenticate with Cognito) but then the write latency will be very high&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks for your time!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "e0acaab0-fe51-11e8-b457-0e86fa5111f4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "js6tmv", "is_robot_indexable": true, "report_reasons": null, "author": "n00b001", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/js6tmv/aws_cognito_multiregion_failover/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/js6tmv/aws_cognito_multiregion_failover/", "subreddit_subscribers": 146176, "created_utc": 1605095693.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "", "author_fullname": "t2_qypz3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing AWS Gateway Load Balancer \u2013 Easy Deployment, Scalability, and High Availability for Partner Appliances | Amazon Web Services", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_jrp7c3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 98, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "networking", "can_mod_post": false, "score": 98, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1605058015.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "aws.amazon.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://aws.amazon.com/blogs/aws/introducing-aws-gateway-load-balancer-easy-deployment-scalability-and-high-availability-for-partner-appliances/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "fa6637dc-fe51-11e8-b451-0e432432760c", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "jrp7c3", "is_robot_indexable": true, "report_reasons": null, "author": "mwarkentin", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/jrp7c3/introducing_aws_gateway_load_balancer_easy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://aws.amazon.com/blogs/aws/introducing-aws-gateway-load-balancer-easy-deployment-scalability-and-high-availability-for-partner-appliances/", "subreddit_subscribers": 146176, "created_utc": 1605029215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "We are wondering how big corporations are managing their multi-account environments in AWS? We are currently evaluating Landing Zone and Control Tower, but neither seems to be suitable for us.\n\nLanding Zone seems to be a collection of Cloud Formation Templates and a couple of step functions, and Control Tower is a managed solution offered by AWS. However, both solutions are limited to new environments and don't allow for importing existing architectures (which I guess would be hard to implement).\n\n* Create new environments and import existing environments\n* Implement the CIS Benchmarks for AWS\n* Create customizable, optimal account structure (e.g., Root, Backup, VPC Management, Security ( IAM ), N Workloads, Shared Services, Audit &amp; Logs, CI / CD, etc. )\n* Sane DevSecOps defaults: Cloudtrail, KMS, Macie, Guard Duty, Config, DNS Flow Logs, etc.\n* IAM: SSO / Federation, Cross Account Access Management\n* SASS Bindings, e.g., Elastic.co VPC Peering\n\nThinking about this a bit further, if not existing yet, a product for creating and managing Landing Zone in multiple clouds would be cool. Also, to enable Dev Teams to provision accounts in a self-service manner. This could be done with a rather cloud-agnostic technology ( e.g., Terraform ) and an abstraction layer on top of it.\n\nIs anyone aware of such a solution? Also, what are your struggles when working with Landing Zones?", "author_fullname": "t2_4pp2ns5g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "State of the Art Landing Zone", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_js6coz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "discussion", "can_mod_post": false, "score": 3, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1605122105.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are wondering how big corporations are managing their multi-account environments in AWS? We are currently evaluating Landing Zone and Control Tower, but neither seems to be suitable for us.&lt;/p&gt;\n\n&lt;p&gt;Landing Zone seems to be a collection of Cloud Formation Templates and a couple of step functions, and Control Tower is a managed solution offered by AWS. However, both solutions are limited to new environments and don&amp;#39;t allow for importing existing architectures (which I guess would be hard to implement).&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Create new environments and import existing environments&lt;/li&gt;\n&lt;li&gt;Implement the CIS Benchmarks for AWS&lt;/li&gt;\n&lt;li&gt;Create customizable, optimal account structure (e.g., Root, Backup, VPC Management, Security ( IAM ), N Workloads, Shared Services, Audit &amp;amp; Logs, CI / CD, etc. )&lt;/li&gt;\n&lt;li&gt;Sane DevSecOps defaults: Cloudtrail, KMS, Macie, Guard Duty, Config, DNS Flow Logs, etc.&lt;/li&gt;\n&lt;li&gt;IAM: SSO / Federation, Cross Account Access Management&lt;/li&gt;\n&lt;li&gt;SASS Bindings, e.g., Elastic.co VPC Peering&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thinking about this a bit further, if not existing yet, a product for creating and managing Landing Zone in multiple clouds would be cool. Also, to enable Dev Teams to provision accounts in a self-service manner. This could be done with a rather cloud-agnostic technology ( e.g., Terraform ) and an abstraction layer on top of it.&lt;/p&gt;\n\n&lt;p&gt;Is anyone aware of such a solution? Also, what are your struggles when working with Landing Zones?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "962d796e-fa9c-11e8-a3dc-0e1ba4fe1be4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "js6coz", "is_robot_indexable": true, "report_reasons": null, "author": "soerenmartius", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/js6coz/state_of_the_art_landing_zone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/js6coz/state_of_the_art_landing_zone/", "subreddit_subscribers": 146176, "created_utc": 1605093305.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "I want to limit HTTP requests to my S3 bucket trough a Cloudfront distribution.\n\nI've been able to get this to work to some extend: now GET request will only succeed when making a req. like this: `https://CLOUDFRONT_URL.cloudfront.net/OBJECT_KEY.jpeg`\n\nHowever, setting up the Cloudfront distribution caused my server (NodeJS/Express/MulterS3) not to be able to make POST requests, i.a. adding objects to the bucket.\n\nHow can I enable POST requests from my server?", "author_fullname": "t2_fm687c8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to make a POST request to a S3 bucket using a Cloudfront distribution?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": true, "name": "t3_js7lry", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "containers", "can_mod_post": false, "score": 1, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1605128055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to limit HTTP requests to my S3 bucket trough a Cloudfront distribution.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been able to get this to work to some extend: now GET request will only succeed when making a req. like this: &lt;code&gt;https://CLOUDFRONT_URL.cloudfront.net/OBJECT_KEY.jpeg&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;However, setting up the Cloudfront distribution caused my server (NodeJS/Express/MulterS3) not to be able to make POST requests, i.a. adding objects to the bucket.&lt;/p&gt;\n\n&lt;p&gt;How can I enable POST requests from my server?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "bf3f5328-fe51-11e8-b6c5-0e68a18374d4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "js7lry", "is_robot_indexable": true, "report_reasons": null, "author": "CryptoScience", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/js7lry/how_to_make_a_post_request_to_a_s3_bucket_using_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/js7lry/how_to_make_a_post_request_to_a_s3_bucket_using_a/", "subreddit_subscribers": 146176, "created_utc": 1605099255.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "I\u2019m working on a REST API that queries the Cognito User Group and is able to change the users.  I was able to make this through Amplify. \n\nAmplify sets up the API to only have the Authorization to a specific User Group. I\u2019d like to access the API from the specific User Group and a Lamda. \n\nHow do I set up the authorization for that?", "author_fullname": "t2_5lkc0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Authorization for API Gateway", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_js1l5v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "serverless", "can_mod_post": false, "score": 4, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1605098641.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m working on a REST API that queries the Cognito User Group and is able to change the users.  I was able to make this through Amplify. &lt;/p&gt;\n\n&lt;p&gt;Amplify sets up the API to only have the Authorization to a specific User Group. I\u2019d like to access the API from the specific User Group and a Lamda. &lt;/p&gt;\n\n&lt;p&gt;How do I set up the authorization for that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ff0e4f90-fe51-11e8-995f-0e494176cf40", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "js1l5v", "is_robot_indexable": true, "report_reasons": null, "author": "tnorlund", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/js1l5v/authorization_for_api_gateway/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/js1l5v/authorization_for_api_gateway/", "subreddit_subscribers": 146176, "created_utc": 1605069841.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "I had to restore our test database a few weeks ago (developers writing crap code... what can I say?), and it frustrated me a little. Our infrastructure (including the Aurora instance) is in terraform plans, as it should be. However, I can't restore a snapshot to an existing instance of a database, so I renamed the existing instance and tried to re-create what was in the terraform plan by hand. That turned out to be in-exact and time-consuming. I can live with this for test (and maybe stage), but should the need arise - this is not a great process for our production database.\n\nSo - how do you handle this? Am I missing a trick?\n\nWe're using Aurora/Postgres 10.11.", "author_fullname": "t2_4awok", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Restoring an Aurora Database from a Snapshot", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": true, "name": "t3_js6w6g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "technical question", "can_mod_post": false, "score": 1, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1605124838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had to restore our test database a few weeks ago (developers writing crap code... what can I say?), and it frustrated me a little. Our infrastructure (including the Aurora instance) is in terraform plans, as it should be. However, I can&amp;#39;t restore a snapshot to an existing instance of a database, so I renamed the existing instance and tried to re-create what was in the terraform plan by hand. That turned out to be in-exact and time-consuming. I can live with this for test (and maybe stage), but should the need arise - this is not a great process for our production database.&lt;/p&gt;\n\n&lt;p&gt;So - how do you handle this? Am I missing a trick?&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re using Aurora/Postgres 10.11.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "e0acaab0-fe51-11e8-b457-0e86fa5111f4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "js6w6g", "is_robot_indexable": true, "report_reasons": null, "author": "ocularsinister2", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/js6w6g/restoring_an_aurora_database_from_a_snapshot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/js6w6g/restoring_an_aurora_database_from_a_snapshot/", "subreddit_subscribers": 146176, "created_utc": 1605096038.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "Hi Guys, just wanted to put this info out there:\n\nI regularly upload files to S3.\n\nToday I created a new bucket to be used with Glacier and the upload speed was 150 Kbps instead of my usual 2Mbps.\n\nSearched threads online and no solutions.\n\nThen I figured it out:\n\nIn my usual uploads the program I use (Syncback Pro) compressess the files to zip before uploading.\n\nIn this profile I was uploading uncompressed files (eg: mp4 instead of zip)\n\nAs soon as I activated compression again, the upload speed returned to normal. Made several tests with and without file compression activated and this was the only factor changing the upload speed.\n\nGlacier or S3 storage class did not make any difference, just the .zip file extension.\n\nThis is very weird!", "author_fullname": "t2_7chfsfv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Glacier or S3 very slow upload", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": true, "name": "t3_js6nwf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "storage", "can_mod_post": false, "score": 1, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1605123714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Guys, just wanted to put this info out there:&lt;/p&gt;\n\n&lt;p&gt;I regularly upload files to S3.&lt;/p&gt;\n\n&lt;p&gt;Today I created a new bucket to be used with Glacier and the upload speed was 150 Kbps instead of my usual 2Mbps.&lt;/p&gt;\n\n&lt;p&gt;Searched threads online and no solutions.&lt;/p&gt;\n\n&lt;p&gt;Then I figured it out:&lt;/p&gt;\n\n&lt;p&gt;In my usual uploads the program I use (Syncback Pro) compressess the files to zip before uploading.&lt;/p&gt;\n\n&lt;p&gt;In this profile I was uploading uncompressed files (eg: mp4 instead of zip)&lt;/p&gt;\n\n&lt;p&gt;As soon as I activated compression again, the upload speed returned to normal. Made several tests with and without file compression activated and this was the only factor changing the upload speed.&lt;/p&gt;\n\n&lt;p&gt;Glacier or S3 storage class did not make any difference, just the .zip file extension.&lt;/p&gt;\n\n&lt;p&gt;This is very weird!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "cb32bd78-fe51-11e8-8357-0e3adcef64d8", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "js6nwf", "is_robot_indexable": true, "report_reasons": null, "author": "Cultural-Water-2172", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/js6nwf/glacier_or_s3_very_slow_upload/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/js6nwf/glacier_or_s3_very_slow_upload/", "subreddit_subscribers": 146176, "created_utc": 1605094914.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "So, i am trying to deploy my django project. I am using supervisor to invoke celery in the background. Below is the supervisor.conf file:  \n\n\n    ; Sample supervisor config file.\n    ;\n    ; For more information on the config file, please see:\n    ; http://supervisord.org/configuration.html\n    ;\n    ; Notes:\n    ;  - Shell expansion (\"~\" or \"$HOME\") is not supported.  Environment\n    ;    variables can be expanded using this syntax: \"%(ENV_HOME)s\".\n    ;  - Quotes around values are not supported, except in the case of\n    ;    the environment= options as shown below.\n    ;  - Comments must have a leading space: \"a=b ;comment\" not \"a=b;comment\".\n    ;  - Command will be truncated if it looks like a config file comment, e.g.\n    ;    \"command=bash -c 'foo ; bar'\" will truncate to \"command=bash -c 'foo \".\n    ;\n    ; Warning:\n    ;  Paths throughout this example file use /tmp because it is available on most\n    ;  systems.  You will likely need to change these to locations more appropriate\n    ;  for your system.  Some systems periodically delete older files in /tmp.\n    ;  Notably, if the socket file defined in the [unix_http_server] section below\n    ;  is deleted, supervisorctl will be unable to connect to supervisord.\n    \n    [unix_http_server]\n    file=/tmp/supervisor.sock   ; the path to the socket file\n    ;chmod=0700                 ; socket file mode (default 0700)\n    ;chown=nobody:nogroup       ; socket file uid:gid owner\n    ;username=user              ; default is no username (open server)\n    ;password=123               ; default is no password (open server)\n    \n    ; Security Warning:\n    ;  The inet HTTP server is not enabled by default.  The inet HTTP server is\n    ;  enabled by uncommenting the [inet_http_server] section below.  The inet\n    ;  HTTP server is intended for use within a trusted environment only.  It\n    ;  should only be bound to localhost or only accessible from within an\n    ;  isolated, trusted network.  The inet HTTP server does not support any\n    ;  form of encryption.  The inet HTTP server does not use authentication\n    ;  by default (see the username= and password= options to add authentication).\n    ;  Never expose the inet HTTP server to the public internet.\n    \n    ;[inet_http_server]         ; inet (TCP) server disabled by default\n    ;port=127.0.0.1:9001        ; ip_address:port specifier, *:port for all iface\n    ;username=user              ; default is no username (open server)\n    ;password=123               ; default is no password (open server)\n    \n    [supervisord]\n    logfile=/tmp/supervisord.log ; main log file; default $CWD/supervisord.log\n    logfile_maxbytes=50MB        ; max main logfile bytes b4 rotation; default 50MB\n    logfile_backups=10           ; # of main logfile backups; 0 means none, default 10\n    loglevel=info                ; log level; default info; others: debug,warn,trace\n    pidfile=/tmp/supervisord.pid ; supervisord pidfile; default supervisord.pid\n    nodaemon=false               ; start in foreground if true; default false\n    silent=false                 ; no logs to stdout if true; default false\n    minfds=1024                  ; min. avail startup file descriptors; default 1024\n    minprocs=200                 ; min. avail process descriptors;default 200\n    ;umask=022                   ; process file creation umask; default 022\n    ;user=supervisord            ; setuid to this UNIX account at startup; recommended if root\n    ;identifier=supervisor       ; supervisord identifier, default is 'supervisor'\n    ;directory=/tmp              ; default is not to cd during start\n    ;nocleanup=true              ; don't clean up tempfiles at start; default false\n    ;childlogdir=/tmp            ; 'AUTO' child log dir, default $TEMP\n    ;environment=KEY=\"value\"     ; key value pairs to add to environment\n    ;strip_ansi=false            ; strip ansi escape codes in logs; def. false\n    \n    ; The rpcinterface:supervisor section must remain in the config file for\n    ; RPC (supervisorctl/web interface) to work.  Additional interfaces may be\n    ; added by defining them in separate [rpcinterface:x] sections.\n    \n    [rpcinterface:supervisor]\n    supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface\n    \n    ; The supervisorctl section configures how supervisorctl will connect to\n    ; supervisord.  configure it match the settings in either the unix_http_server\n    ; or inet_http_server section.\n    \n    [program:celeryd]\n    command=/var/app/venv/staging-LQM1lest/bin/celery -A main worker --loglevel=info\n    stdout_logfile=/mountpoint/packages/celeryd.log\n    stderr_logfile=/mountpoint/packages/celeryd.log\n    autostart=true\n    autorestart=true\n    startsecs=10\n    stopwaitsecs=600\n    \n    [program:celerybeat]\n    command=/var/app/venv/staging-LQM1lest/bin/celery -A main beat --pidfile=\"/tmp/celerybeat.pid\"\n    stdout_logfile=/mountpoint/packages/celerybeat.log\n    stderr_logfile=/mountpoint/packages/celerybeat.log\n    autostart=true\n    autorestart=true\n    startsecs=10\n    stopwaitsecs=600\n    \n    [supervisorctl]\n    serverurl=unix:///tmp/supervisor.sock ; use a unix:// URL  for a unix socket\n    ;serverurl=http://127.0.0.1:9001 ; use an http:// url to specify an inet socket\n    ;username=chris              ; should be same as in [*_http_server] if set\n    ;password=123                ; should be same as in [*_http_server] if set\n    ;prompt=mysupervisor         ; cmd line prompt (default \"supervisor\")\n    ;history_file=~/.sc_history  ; use readline history if available\n    \n    ; The sample program section below shows all possible program subsection values.\n    ; Create one or more 'real' program: sections to be able to control them under\n    ; supervisor.\n    \n    \n    ;[include]\n    ;files = relative/directory/*.ini\n    \n\nand this is my \".ebextensions/build.config\" file commands the last command is to invoke the supervisord\n\n    commands:\n        command1:\n            command: \"test -f /usr/bin/google-chrome || wget https://dl.google.com/linux/direct/google-chrome-stable_current_x86_64.rpm\"\n        command2:\n            command: \"test -f /usr/bin/google-chrome || sudo yum -y install ./google-chrome-stable_current_x86_64.rpm\"\n        command3:\n            command: \"sudo cp -r /home/ec2-user/nltk_data /usr/share/nltk_data\"\n        command4:\n            command: \"test -f /usr/bin/supervisord || sudo amazon-linux-extras install -y epel\"\n        command5:\n            command: \"test -f /usr/bin/supervisord || sudo yum install -y supervisor\"\n        command6:\n            command: \"test -e /tmp/supervisor.sock &amp;&amp; sudo unlink /tmp/supervisor.sock\"\n        command7:\n            command: \"/usr/bin/supervisord -c /var/app/current/supervisord.conf\"\n            cwd: \"/var/app/current\" \n\nMy celery worker is working but in the celerybeat log i get this error:\n\n    shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n    Traceback (most recent call last):\n      File \"/var/app/venv/staging-LQM1lest/bin/celery\", line 8, in &lt;module&gt;\n        sys.exit(main())\n      File \"/var/app/venv/staging-LQM1lest/lib/python3.7/site-packages/celery/__main__.py\", line 16, in main\n        _main()\n      File \"/var/app/venv/staging-LQM1lest/lib/python3.7/site-packages/celery/bin/celery.py\", line 322, in main\n        cmd.execute_from_commandline(argv)\n      File \"/var/app/venv/staging-LQM1lest/lib/python3.7/site-packages/celery/bin/celery.py\", line 499, in execute_from_commandline\n        super(CeleryCommand, self).execute_from_commandline(argv)))\n      File \"/var/app/venv/staging-LQM1lest/lib/python3.7/site-packages/celery/bin/base.py\", line 289, in execute_from_commandline\n        argv = self.setup_app_from_commandline(argv)\n      File \"/var/app/venv/staging-LQM1lest/lib/python3.7/site-packages/celery/bin/base.py\", line 509, in setup_app_from_commandline\n        self.app = self.find_app(app)\n      File \"/var/app/venv/staging-LQM1lest/lib/python3.7/site-packages/celery/bin/base.py\", line 531, in find_app\n        return find_app(app, symbol_by_name=self.symbol_by_name)\n      File \"/var/app/venv/staging-LQM1lest/lib/python3.7/site-packages/celery/app/utils.py\", line 373, in find_app\n        sym = symbol_by_name(app, imp=imp)\n      File \"/var/app/venv/staging-LQM1lest/lib/python3.7/site-packages/celery/bin/base.py\", line 534, in symbol_by_name\n        return imports.symbol_by_name(name, imp=imp)\n      File \"/var/app/venv/staging-LQM1lest/lib/python3.7/site-packages/kombu/utils/imports.py\", line 57, in symbol_by_name\n        module = imp(module_name, package=package, **kwargs)\n      File \"/var/app/venv/staging-LQM1lest/lib/python3.7/site-packages/celery/utils/imports.py\", line 110, in import_from_cwd\n        with cwd_in_path():\n      File \"/usr/lib64/python3.7/contextlib.py\", line 112, in __enter__\n        return next(self.gen)\n      File \"/var/app/venv/staging-LQM1lest/lib/python3.7/site-packages/celery/utils/imports.py\", line 61, in cwd_in_path\n        cwd = os.getcwd()\n    FileNotFoundError: [Errno 2] No such file or directory\n\nCould really use a help here.", "author_fullname": "t2_isn0e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting error while deploying django with celery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_js6ie7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "technical question", "can_mod_post": false, "score": 1, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1605122959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, i am trying to deploy my django project. I am using supervisor to invoke celery in the background. Below is the supervisor.conf file:  &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;; Sample supervisor config file.\n;\n; For more information on the config file, please see:\n; http://supervisord.org/configuration.html\n;\n; Notes:\n;  - Shell expansion (&amp;quot;~&amp;quot; or &amp;quot;$HOME&amp;quot;) is not supported.  Environment\n;    variables can be expanded using this syntax: &amp;quot;%(ENV_HOME)s&amp;quot;.\n;  - Quotes around values are not supported, except in the case of\n;    the environment= options as shown below.\n;  - Comments must have a leading space: &amp;quot;a=b ;comment&amp;quot; not &amp;quot;a=b;comment&amp;quot;.\n;  - Command will be truncated if it looks like a config file comment, e.g.\n;    &amp;quot;command=bash -c &amp;#39;foo ; bar&amp;#39;&amp;quot; will truncate to &amp;quot;command=bash -c &amp;#39;foo &amp;quot;.\n;\n; Warning:\n;  Paths throughout this example file use /tmp because it is available on most\n;  systems.  You will likely need to change these to locations more appropriate\n;  for your system.  Some systems periodically delete older files in /tmp.\n;  Notably, if the socket file defined in the [unix_http_server] section below\n;  is deleted, supervisorctl will be unable to connect to supervisord.\n\n[unix_http_server]\nfile=/tmp/supervisor.sock   ; the path to the socket file\n;chmod=0700                 ; socket file mode (default 0700)\n;chown=nobody:nogroup       ; socket file uid:gid owner\n;username=user              ; default is no username (open server)\n;password=123               ; default is no password (open server)\n\n; Security Warning:\n;  The inet HTTP server is not enabled by default.  The inet HTTP server is\n;  enabled by uncommenting the [inet_http_server] section below.  The inet\n;  HTTP server is intended for use within a trusted environment only.  It\n;  should only be bound to localhost or only accessible from within an\n;  isolated, trusted network.  The inet HTTP server does not support any\n;  form of encryption.  The inet HTTP server does not use authentication\n;  by default (see the username= and password= options to add authentication).\n;  Never expose the inet HTTP server to the public internet.\n\n;[inet_http_server]         ; inet (TCP) server disabled by default\n;port=127.0.0.1:9001        ; ip_address:port specifier, *:port for all iface\n;username=user              ; default is no username (open server)\n;password=123               ; default is no password (open server)\n\n[supervisord]\nlogfile=/tmp/supervisord.log ; main log file; default $CWD/supervisord.log\nlogfile_maxbytes=50MB        ; max main logfile bytes b4 rotation; default 50MB\nlogfile_backups=10           ; # of main logfile backups; 0 means none, default 10\nloglevel=info                ; log level; default info; others: debug,warn,trace\npidfile=/tmp/supervisord.pid ; supervisord pidfile; default supervisord.pid\nnodaemon=false               ; start in foreground if true; default false\nsilent=false                 ; no logs to stdout if true; default false\nminfds=1024                  ; min. avail startup file descriptors; default 1024\nminprocs=200                 ; min. avail process descriptors;default 200\n;umask=022                   ; process file creation umask; default 022\n;user=supervisord            ; setuid to this UNIX account at startup; recommended if root\n;identifier=supervisor       ; supervisord identifier, default is &amp;#39;supervisor&amp;#39;\n;directory=/tmp              ; default is not to cd during start\n;nocleanup=true              ; don&amp;#39;t clean up tempfiles at start; default false\n;childlogdir=/tmp            ; &amp;#39;AUTO&amp;#39; child log dir, default $TEMP\n;environment=KEY=&amp;quot;value&amp;quot;     ; key value pairs to add to environment\n;strip_ansi=false            ; strip ansi escape codes in logs; def. false\n\n; The rpcinterface:supervisor section must remain in the config file for\n; RPC (supervisorctl/web interface) to work.  Additional interfaces may be\n; added by defining them in separate [rpcinterface:x] sections.\n\n[rpcinterface:supervisor]\nsupervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface\n\n; The supervisorctl section configures how supervisorctl will connect to\n; supervisord.  configure it match the settings in either the unix_http_server\n; or inet_http_server section.\n\n[program:celeryd]\ncommand=/var/app/venv/staging-LQM1lest/bin/celery -A main worker --loglevel=info\nstdout_logfile=/mountpoint/packages/celeryd.log\nstderr_logfile=/mountpoint/packages/celeryd.log\nautostart=true\nautorestart=true\nstartsecs=10\nstopwaitsecs=600\n\n[program:celerybeat]\ncommand=/var/app/venv/staging-LQM1lest/bin/celery -A main beat --pidfile=&amp;quot;/tmp/celerybeat.pid&amp;quot;\nstdout_logfile=/mountpoint/packages/celerybeat.log\nstderr_logfile=/mountpoint/packages/celerybeat.log\nautostart=true\nautorestart=true\nstartsecs=10\nstopwaitsecs=600\n\n[supervisorctl]\nserverurl=unix:///tmp/supervisor.sock ; use a unix:// URL  for a unix socket\n;serverurl=http://127.0.0.1:9001 ; use an http:// url to specify an inet socket\n;username=chris              ; should be same as in [*_http_server] if set\n;password=123                ; should be same as in [*_http_server] if set\n;prompt=mysupervisor         ; cmd line prompt (default &amp;quot;supervisor&amp;quot;)\n;history_file=~/.sc_history  ; use readline history if available\n\n; The sample program section below shows all possible program subsection values.\n; Create one or more &amp;#39;real&amp;#39; program: sections to be able to control them under\n; supervisor.\n\n\n;[include]\n;files = relative/directory/*.ini\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;and this is my &amp;quot;.ebextensions/build.config&amp;quot; file commands the last command is to invoke the supervisord&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;commands:\n    command1:\n        command: &amp;quot;test -f /usr/bin/google-chrome || wget https://dl.google.com/linux/direct/google-chrome-stable_current_x86_64.rpm&amp;quot;\n    command2:\n        command: &amp;quot;test -f /usr/bin/google-chrome || sudo yum -y install ./google-chrome-stable_current_x86_64.rpm&amp;quot;\n    command3:\n        command: &amp;quot;sudo cp -r /home/ec2-user/nltk_data /usr/share/nltk_data&amp;quot;\n    command4:\n        command: &amp;quot;test -f /usr/bin/supervisord || sudo amazon-linux-extras install -y epel&amp;quot;\n    command5:\n        command: &amp;quot;test -f /usr/bin/supervisord || sudo yum install -y supervisor&amp;quot;\n    command6:\n        command: &amp;quot;test -e /tmp/supervisor.sock &amp;amp;&amp;amp; sudo unlink /tmp/supervisor.sock&amp;quot;\n    command7:\n        command: &amp;quot;/usr/bin/supervisord -c /var/app/current/supervisord.conf&amp;quot;\n        cwd: &amp;quot;/var/app/current&amp;quot; \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;My celery worker is working but in the celerybeat log i get this error:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\nTraceback (most recent call last):\n  File &amp;quot;/var/app/venv/staging-LQM1lest/bin/celery&amp;quot;, line 8, in &amp;lt;module&amp;gt;\n    sys.exit(main())\n  File &amp;quot;/var/app/venv/staging-LQM1lest/lib/python3.7/site-packages/celery/__main__.py&amp;quot;, line 16, in main\n    _main()\n  File &amp;quot;/var/app/venv/staging-LQM1lest/lib/python3.7/site-packages/celery/bin/celery.py&amp;quot;, line 322, in main\n    cmd.execute_from_commandline(argv)\n  File &amp;quot;/var/app/venv/staging-LQM1lest/lib/python3.7/site-packages/celery/bin/celery.py&amp;quot;, line 499, in execute_from_commandline\n    super(CeleryCommand, self).execute_from_commandline(argv)))\n  File &amp;quot;/var/app/venv/staging-LQM1lest/lib/python3.7/site-packages/celery/bin/base.py&amp;quot;, line 289, in execute_from_commandline\n    argv = self.setup_app_from_commandline(argv)\n  File &amp;quot;/var/app/venv/staging-LQM1lest/lib/python3.7/site-packages/celery/bin/base.py&amp;quot;, line 509, in setup_app_from_commandline\n    self.app = self.find_app(app)\n  File &amp;quot;/var/app/venv/staging-LQM1lest/lib/python3.7/site-packages/celery/bin/base.py&amp;quot;, line 531, in find_app\n    return find_app(app, symbol_by_name=self.symbol_by_name)\n  File &amp;quot;/var/app/venv/staging-LQM1lest/lib/python3.7/site-packages/celery/app/utils.py&amp;quot;, line 373, in find_app\n    sym = symbol_by_name(app, imp=imp)\n  File &amp;quot;/var/app/venv/staging-LQM1lest/lib/python3.7/site-packages/celery/bin/base.py&amp;quot;, line 534, in symbol_by_name\n    return imports.symbol_by_name(name, imp=imp)\n  File &amp;quot;/var/app/venv/staging-LQM1lest/lib/python3.7/site-packages/kombu/utils/imports.py&amp;quot;, line 57, in symbol_by_name\n    module = imp(module_name, package=package, **kwargs)\n  File &amp;quot;/var/app/venv/staging-LQM1lest/lib/python3.7/site-packages/celery/utils/imports.py&amp;quot;, line 110, in import_from_cwd\n    with cwd_in_path():\n  File &amp;quot;/usr/lib64/python3.7/contextlib.py&amp;quot;, line 112, in __enter__\n    return next(self.gen)\n  File &amp;quot;/var/app/venv/staging-LQM1lest/lib/python3.7/site-packages/celery/utils/imports.py&amp;quot;, line 61, in cwd_in_path\n    cwd = os.getcwd()\nFileNotFoundError: [Errno 2] No such file or directory\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Could really use a help here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "e0acaab0-fe51-11e8-b457-0e86fa5111f4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "js6ie7", "is_robot_indexable": true, "report_reasons": null, "author": "mohitus88", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/js6ie7/getting_error_while_deploying_django_with_celery/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/js6ie7/getting_error_while_deploying_django_with_celery/", "subreddit_subscribers": 146176, "created_utc": 1605094159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "Hello, I\u2019m building a web app, and am primarily a php developper. What I\u2019d like to do is have \n- information / brochure part of the site on wordpress\n- the admin of the app on LAMP stack \n- the user facing side of the app on node to have a react native component\n\nI\u2019m completely new to aws and am struggling with the documentation. \n\nIs it possible to configure aws to point to different systems depending on the url?\n\nEg website.com to the wordpress, website.com/login to the admin, and website.com/app to the node.js?", "author_fullname": "t2_1o3zbfu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multiple stacks on AWS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_js67np", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "general aws", "can_mod_post": false, "score": 1, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1605121377.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I\u2019m building a web app, and am primarily a php developper. What I\u2019d like to do is have \n- information / brochure part of the site on wordpress\n- the admin of the app on LAMP stack \n- the user facing side of the app on node to have a react native component&lt;/p&gt;\n\n&lt;p&gt;I\u2019m completely new to aws and am struggling with the documentation. &lt;/p&gt;\n\n&lt;p&gt;Is it possible to configure aws to point to different systems depending on the url?&lt;/p&gt;\n\n&lt;p&gt;Eg website.com to the wordpress, website.com/login to the admin, and website.com/app to the node.js?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "256aecca-fe52-11e8-bc65-0eea6867f0e4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "js67np", "is_robot_indexable": true, "report_reasons": null, "author": "miamiscubi", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/js67np/multiple_stacks_on_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/js67np/multiple_stacks_on_aws/", "subreddit_subscribers": 146176, "created_utc": 1605092577.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "aws", "selftext": "Hi,\n\nI'm looking for a solution (preferably open-source, even if the integration takes more time) allowing to write **custom compliance rules for AWS which can be reused between static and dynamic analysis**.\n\nThe ideal workflow would be:\n\n* Write rules such as \"No public S3 bucket\", \"No EC2 instance with a public IP\", etc.\n* Run static analysis scans against Terraform plans\n* Run dynamic analysis scans against a live AWS account\n\nI believe Snyk and Prisma Cloud have these features, but they cost $$$. I know about several tools capable of performing this kind of static analysis (though few allow to write *custom* rules, tfsec doesn't) and dynamic analysis (AWS Config, CloudCustodian...), but having to write twice the same rule and properly test it sounds sub-optimal at best.\n\nAnything you'd recommend? Thank you!", "author_fullname": "t2_wfsv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Static and dynamic compliance scans (Terraform + live AWS account)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/aws", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "top_awarded_type": null, "hide_score": false, "name": "t3_js4j20", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "security", "can_mod_post": false, "score": 1, "approved_by": null, "author_premium": false, "thumbnail": "", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1605112437.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.aws", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a solution (preferably open-source, even if the integration takes more time) allowing to write &lt;strong&gt;custom compliance rules for AWS which can be reused between static and dynamic analysis&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;The ideal workflow would be:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Write rules such as &amp;quot;No public S3 bucket&amp;quot;, &amp;quot;No EC2 instance with a public IP&amp;quot;, etc.&lt;/li&gt;\n&lt;li&gt;Run static analysis scans against Terraform plans&lt;/li&gt;\n&lt;li&gt;Run dynamic analysis scans against a live AWS account&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I believe Snyk and Prisma Cloud have these features, but they cost $$$. I know about several tools capable of performing this kind of static analysis (though few allow to write &lt;em&gt;custom&lt;/em&gt; rules, tfsec doesn&amp;#39;t) and dynamic analysis (AWS Config, CloudCustodian...), but having to write twice the same rule and properly test it sounds sub-optimal at best.&lt;/p&gt;\n\n&lt;p&gt;Anything you&amp;#39;d recommend? Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b921bc38-fe51-11e8-b892-0e32848ff0d0", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qh84", "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "js4j20", "is_robot_indexable": true, "report_reasons": null, "author": "thorn42", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/aws/comments/js4j20/static_and_dynamic_compliance_scans_terraform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/r/aws/comments/js4j20/static_and_dynamic_compliance_scans_terraform/", "subreddit_subscribers": 146176, "created_utc": 1605083637.0, "num_crossposts": 1, "media": null, "is_video": false}}], "after": "t3_js4j20", "before": null}}